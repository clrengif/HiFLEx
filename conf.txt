## How to used the Scripts
# prepare filelist: run prepare_file_list.py
# every day: run reduction_day.py   : shift orders, determine background, create wavelength solution for the day, create normalised extracted spectrum, extract the spectrum

# Configuration file for:
#   create_badpx_mask.py
#   prepare_file_list.py
#   reduction_day.py
#   order_trace.py  (not used anymore after Jan 18)
#   extract.py      (not used anymore after Jan 18)
#   ident_arc.py    (not used anymore after Sep 17)

## Format of the parameters:
#---------------------------
#   - number of white spaces doesn't matter
#   - lists need to be given with comma between the values. The brakets [] are optional


## General parameters:
#---------------------
# GUI: allows userinput for some of the steps (experimental)
GUI = False


# The folder where the raw data is stored. All file names given in this section need to be given relative to this path, e.g. with leading subfolder if data is stored in a subfolder
raw_data_path           = /local/home/ncook/data_EXOhSPEC/20180605/


# Configuration file in which the processing of the raw data fits files is defined
configfile_fitsfiles = fits_conf.txt

# subframe: gives the size in x (dispersion axis) and y (cross-dispersion axis), and the starting coordinates in x and y in case only a subframe should be used. Needed when reading files
#           possible formats: can be empty, or
#                             [4250,2838,0,0], or
#                             4250,2838,0,0
# for QSI:              subframe        = [4250,2838,0,0]
# for QSI:              subframe        = [4250,1600,0,450]
# for QSI Bill:         subframe        = [2184,1472,0,0]
# for Moravian:         subframe        = [2500,3056,56,0]
# for SBIG:             subframe        = [2750,4096,350,0]
# for HARPS:            subframe        = [4096,2048,0,50]
subframe        = [2184,1472,0,0]

# To extract the data correctly, the frame should be rotated in the way, that traces (dispersion axis) are along vertical direction
#           with wavelength increasing with increasing pixel number (blue on top). 
#           If necessary the image can be flipped after the rotation so that the central wavelength of the orders decreases with increasing 
#           pixel number (blue orders on the right of the (rotated) image and the red orders on the left).
#               format: multiple of 90
# for QSI (both):       rotate_frame = 90
# for Moravian, SBIG:   rotate_frame = 180 or rotate_frame = 0; flip_frame = True
# for HARPS:            rotate_frame = 180
rotate_frame    = 90
flip_frame      = False

# extraction_width_multiplier times the average width of the gaussian fit to the traces of the orders defines how many pixel of either side to extract.
#           format: float or integer
extraction_width_multiplier = 2
arcextraction_width_multiplier = 3
# In order to create a linear wavelength scale, what should the resolution of the scale be in Angstrom
wavelength_scale_resolution = 0.01

## Between observations of different nights the positions of the traces along cross-dispersion axis might change. The pipeline will determine the shift
# maxshift gives the maximum allowed shift between the current sflat and original_master_order_filename.
#           format: float or integer
maxshift = 15
# Also the width of the traces might change. As the measurements are only done on a subsample of the data, the user needs to decide if the new, less precise widths should be used.
update_widths = False

## If the positions of the traces between consecutive observations has changed too much, the orders are searched from scratch and then adjusted.
# bin_search_apertures: Search the apertures of the orders in a binned image. The first value gives the binning along one order (vertical axis, dispersion axis)
#                    and the second value the binning perpendicular to the orders (horizontal, cross-dispersion axis). 
#                    Heavy binning along the dispersion axis is possible in this step, while binning in cross-dispersion needs to be significantly smaller than the minimum separation between orders.
# for QSI:              bin_search_apertures = 20,5
# for Moravian, SBIG:   bin_search_apertures = 20,4
# for HARPS:            bin_search_apertures = 20,2
bin_search_apertures    = 20,2
# bin_adjust_apertures: Adjust the center of the apertures in a less binned image. Description as for bin_search_apertures. The second value should be 1 to reach best precission
bin_adjust_apertures    = 3,1
# polynom_order_apertures: Order of the polynomial to define the form of the traces along the CCD
polynom_order_apertures = 5
# width_percentile: What part of the height should be used in order to define the width of the orders? width_percentile = 50 coesponds to the FWHM
width_percentile        = 50


## To determine the background
# background_width_multiplier defines the area which is excluded for determining the background. It has the same settings as extraction_width_multiplier.
# The first value is for the science and the second for the calibration traces
background_width_multiplier = [3, 1]
# polynom_bck defines the orders for a 2d polynomial that is fitted to the background. The first value is for dispersion and the second for cross-dispersion direction.
polynom_bck = [4, 4]

## Finding the traces of the calibration fiber 
# arcshift_side: On which side of the science orders are the corresponding calibration orders located. Possible values are 
#               "left" (towards the redder order), "right" (to the bluer order), or "center" (same position as the science orders
# for HARPS, QSI Bill:        arcshift_side = left
# for SBIG:                   arcshift_side = right
arcshift_side = left
# arcshift_range: Range to search for the shift between the flat traces and arc_traces. This value is determinded by the the script, only in case the process fails the parameter is used.
arcshift_range  = [25, 60]

## The following parameters define the search area when finding the new wavelength solution for the night by using an old solution
# order_offset: Search range to find out by how many orders are the two solutions shifted? Normally the change should be less than 1 Order. The offset will be negative, if redder orders are added.
order_offset = [-1,1]
# px_offset: search range and step size to find out by how much the central pixel of the orders was shifted. Normally the change should be less than 100 pixel. Sign is the pixel shift from old to new.
px_offset = [-100, 100, 10]
# px_offset_order: Additional shift per order in case big variations happened.
px_offset_order = [-1, 1, 1]
# resultion_offset_pct: Percentage of how much the resolution between the solutions changes. The value is applied in both directions, in total 11 steps will be made. Normally 3 percent should be fine
resolution_offset_pct = 3

## The following parameter define the adjustments made for the wavelength solution. Thereby the process starts with a rugh wavelength solution and ends with a much better one. 5 steps with 10 iterations each are done
# polynom_order_traces: order of a polynomial fit for rough and final solution to fit the wavelength against line position in each order. 
#                       For a setup not covering a full order [2,4] should be fine. a final value of 3 is not enough to reflect the position of the lines on the CCD
#                       For a setup covering a full order or more than 20 orders [2,5] might be necessary
polynom_order_traces = [4,4]
# polynom_order_intertrace: order for rough and final solution to fit the parameters of the polynomials between the orders. Normally 2 should be fine
polynom_order_intertraces = 4
# opt_px_range: What fraction around the central pixel of each order should be used to corellate lines in the arc spectrum with the reference spectrum. Normally [0.6, 1.0] is good.
#               If the previous solution differs a lot at the edges of the orders, than the first value should be smaller.
#               If the previous solution matches nearly exactly the current solution, then both value can be bigger, e.g. [0.8,2]
opt_px_range = [0.9, 1.0]
# diff_pxs: What is the maximum difference between wavelength solution and reference line in order to assigned the lines together.
#           A good value is 8px, can be higher as sigma-clipping is performed to get rid of badly assigned lines. The Gaussian width of the emission lines is used in the final asignment
diff_pxs = 8


## general filenames which should be the same for a long time.
# Path and filename to the badpixel mask. Created by create_badpx_mask.py
badpx_mask_filename = /data/ronny/Reduced/NA/bad_px_mask.fits

# Path and filename to the file with the previous found positions of the orders and the previous wavelength solution.
#   If the files don't exist, a solution is created from scratch 
#       For original_master_wavelensolution_filename this means: File arc_lines_wavelength.txt needs to be created in order to create the wavelength solution. 
#                                                                        The wavelength solution created from arc_lines_wavelength.txt will be saved in original_master_wavelensolution_filename.
#                                                                If no wavelength solution is necessay, it can set to "pseudo".
original_master_traces_filename = /data/ronny/Reduced/2018NA/master_traces_sci.fits
original_master_wavelensolution_filename = /data/ronny/Reduced/20180220/master_wavelength.fits

# Path and filename to the file with the catalog lines. The file must contain tab-separated wavelength, line strength, and element. The values can be used as given from the NIST database, e.g. 6550.653 \t 140* \t Ne II 
reference_catalog = /home/ronny/Scripts/exohspec/reference_lines_UNe.txt
reference_catalog = /home/ronny/Scripts/exohspec/reference_lines_ThAr.txt
# The Script runs arc solution in Angstrom. Give the multiplier for the wavelength to get Angstrom, e.g. catalog_file_wavelength_muliplier=10 for the reference_catalog in [nm]
catalog_file_wavelength_muliplier = 1

use_catalog_lines = NeI, UI, ThI, ArI


## Raw data information:
#-----------------------
raw_data_file_endings   = .fit, .fits
raw_data_file_list      = file_list_raw_data.txt
raw_data_imtyp_keyword  = IMAGETYP
raw_data_imtyp_bias     = Bias Frame
raw_data_imtyp_dark     = Dark Frame
raw_data_imtyp_flat     = Flat Frame
raw_data_imtyp_trace1   = NA
raw_data_imtyp_flatarc  = NA
raw_data_imtyp_trace2   = NA
raw_data_exptim_keyword = EXPTIME
raw_data_dateobs_keyword = DATE-OBS
# HARPS:
# raw_data_imtyp_keyword  = OBJECT
# raw_data_imtyp_bias     = BIAS,BIAS
# raw_data_imtyp_trace1   = LAMP,DARK,TUN
# raw_data_imtyp_trace2   = WAVE,WAVE,THAR2
# raw_data_imtyp_flatarc  = LAMP,LAMP,TUN

# For each type of calibration filetype (e.g. bias, darks) a <filetype>_calibs_create gives the information which corrections will be applied before the <filetype>_rawfiles are combined.
#   Corrections will applied in the order given!
# The <filetype>_calibs_create_g define thereby the general values, which will be assinged by prepare_file_list.py to <filetype>_calibs_create
#   The following settings are possible (case-insensitive): subframe, badpx_mask, bias, dark, flat, background, localbackground, normalise, combine_mean, combine_sum. Please check the manual for more information
#   For dark calibration darks with the correct exposure time will be used. 
#   For background the key 'background_filename' needs to be defined
bias_calibs_create_g            = [subframe, badpx_mask]
dark_calibs_create_g            = [subframe, badpx_mask, bias]
rflat_calibs_create_g           = subframe, badpx_mask, dark, bias, normalise
# The file types for the calibrations listed above are applied as CCD image
# The file types for the calibrations listed below are used to find extracted data
trace1_calibs_create_g          = subframe, badpx_mask, dark, bias
trace2_calibs_create_g          = [subframe, badpx_mask, dark, bias]
arc_calibs_create_g             = [subframe, badpx_mask, dark, bias, localbackground]
flatarc_calibs_create_g         = [subframe, badpx_mask, dark, bias, rflat, localbackground]
extract_calibs_create_g         = [subframe, badpx_mask, dark, bias, rflat, localbackground]
wavelengthcal_calibs_create_g   = [subframe, badpx_mask]
# Standard calibrations to be done, if no other information is given
standard_calibs_create = []

# when reading already processed images from the result path, this defines what calibrations should be done. If one file type should be handled different, then <filetype>_calibs_read can be used
calibs_read = [subframe]


## Result storage information:
#-----------------------------
# The folder where the result data is stored
result_path = .

# In the reduced images mark pixels above max_good_value as saturated
#           format: float or integer
# SBIG:         max_good_value = 46000
# all others:   max_good_value = 63000
max_good_value  = 63000

# csv files for Terra:
csv_path   = Object1/data/

## extracted data:
#-----------------
# path for the extracted data (ceres format / single files for extracted spectrum and wavelength)
path_extraction             = extracted
path_extraction_single      = extracted/single
# BITPIX of the extracted fits-file (-32, -64, everything else: -64)
extracted_bitpix            = -64

## reduced images:
#-----------------
# The reduced images can be saved, if a path instead of "NA" is given path_reduced
path_reduced                = reduced_images
path_reduced                = NA

## Standard filenames:
#---------------------
# master file for the orders of the scientific traces, of the arc traces, and the normalised extracted flat spectrum. Created by reduction_day.py
master_trace_sci_filename           = master_traces_sci.fits
master_trace_cal_filename           = master_traces_cal.fits
master_wavelensolution_filename     = master_wavelength.fits
master_flat_spec_norm_filename      = master_flat_spec_norm.fits
master_wavelengths_shift_filename   = master_wavelengths_shift.txt

# master file for identifiying which pixel contain background. Created by reduction_day.py
background_px_filename          = background_px.fits

# master file for the background correction. Created by reduction_day.py
background_filename             = background.fits

# RV analysis
rv_models_ceres                 = /home/ronny/software/ceres-master/data/COELHO_MODELS/R_40000b/
path_rv                         = rv_output

## Logging:
#----------
logging_path                        = logging
logging_trace1_binned               = mstr_trace1_binned.fits
logging_traces_binned               = sci_trace1_binned.fits
logging_traces_im_binned            = traces_in_master_trace1_binned.png
logging_traces_im                   = traces_in_master_trace1.png
logging_find_arc_traces             = arctraces_find.png
logging_arctraces_im                = arctraces_in_master_arc.png
logging_map_shift_orders            = map_shifts.fits
logging_orig_for_background         = orig_for_background_map.fits
logging_found_arc_lines             = arc_lines_found.txt
logging_identified_arc_lines        = arc_lines_identified.txt
logging_wavelength_solution_form    = wavelength_solution_form.png
logging_em_lines_gauss_width_form   = wavelength_solution_emmission_lines_gaussian_width.png
logging_arc_line_identification_residuals = arc_line_identification_residuals.png
logging_arc_line_identification_spectrum  = arc_line_identification_spectrum.pdf
logging_arc_line_identification_positions = arc_line_identification_positions.png


