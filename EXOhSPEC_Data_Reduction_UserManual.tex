\documentclass[10pt,a4paper]{article}

\usepackage{listings}              % Only used for this template to display code, can delete
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}    %Driver-independent color extensions
\usepackage[linktocpage=true]{hyperref}            % Extensive support for hypertext in LaTeX
\usepackage{graphicx}              % Enhanced support for graphics
\usepackage{amsmath}

\newcommand\tab[1][1cm]{\hspace*{#1}}

\hypersetup{
    pdfauthor={Neil Cook, Ronny Errmann},
    pdfcreator={Neil Cook, Ronny Errmann},
    pdftitle={EXOhSPEC Data Reduction User Manual},
    pdfsubject={Subject of thesis here},
    pdfkeywords={thesis keywords here},
    colorlinks=true,         % false: boxed links; true: colored links
    linkcolor=blue,          % color of internal links (change box color with linkbordercolor)
    citecolor=Maroon,        % color of links to bibliography
    filecolor=blue,          % color of file links
    urlcolor=blue,           % color of external links
    plainpages=false,       
}

% This is only used if you want to add code
\lstdefinestyle{base}{
  basicstyle=\small\ttfamily,
  backgroundcolor=\color{Tan},
  language=[LaTeX]{TeX},
  moredelim=**[is][\color{red}]{@}{@},
}

\title{User Manual for Data Reduction of the EXOhSPEC Instrument \\ Working version: V0.0.1}
\date{January, 2018}
\author{Neil Cook, Ronny Errmann\\ Physics, Astronomy and Maths, University of Hertfordshire}

\begin{document}

\maketitle

\pagenumbering{Roman}
\tableofcontents
\pagenumbering{arabic}

% -------------------------------------------------------------------------------------------



\section{Introduction}
\label{intro}



% -------------------------------------------------------------------------------------------

This program is designed to take a fits image file (i.e. a CCD image) and extract out orders from an Echelle spectrograph (regardless of separation and curvature, as long as orders are distinguishable from one-another). 

% -------------------------------------------------------------------------------------------


\newpage
\section{Installation and dependencies}
\label{installation}

\noindent This program was written to work with modules installed in Anaconda 2 and python 2.7. It is recommended to use an installation of anaconda 2 to use this program (If this is not possible, the whole module dependency is given in Appendix~\ref{section:module_dependency}).

% -------------------------------------------------------------------------------------------

\subsection{With Anaconda and python 2.7}

\noindent Anaconda can be downloaded from \url{https://www.continuum.io/downloads}. Please select the version for python 2.7. After download it can be installed by running
\begin{lstlisting}[style=base]
sh Downloads/Anaconda2-5.0.1-Linux-x86_64.sh
\end{lstlisting}
(no superuser permissions are needed).

After the installation and opening a new terminal python should point to the one in the Anaconda installation. It can be checked by running \verb|which python| . If the result doesn't point to your Anaconda installation, but somewhere else (e.g. \verb|/usr/bin/python|), an extra entry into \verb|.bashrc| or \verb|.tcshrc| needs to be added. If you use \verb|bash| add the following line (replace \textit{/home/exohspec} by the path you used for the installation to your \verb|.bashrc|. %, \textit{/home/\textless username\textgreater} is the standard installation path)
\begin{lstlisting}[style=base]
export PATH="/home/exohspec/anaconda2/bin:$PATH"
\end{lstlisting}
If you use \verb|csh| add the following line (replace \textit{/home/exohspec} by the path you used for the installation to your \verb|.tcshrc|
\begin{lstlisting}[style=base]
setenv PATH /home/exohspec/anaconda2/bin\:$PATH
\end{lstlisting}

After making the change and opening a new terminal python should point to the file in the Anaconda installation (\verb|which python|).

\subsubsection{Additional modules}

\noindent Once Anaconda is installed one other module is needed (tqdm). If Anaconda is installed correctly then pip can be used to install this module
\begin{lstlisting}[style=base]
pip install tqdm
\end{lstlisting}



\subsection{Necessary python files}

\noindent The following files need to be located in the program folder:
\begin{description}
\item[create\_badpx\_mask.py] Script to create a bad pixel mask.
\item[prepare\_file\_list.py] Script to automatically assign the fits files into the corresponding calibration steps.
\item[reduction\_day.py] Script which needs to be run on each new set of data. It creates the data, which is necessary in order to extract the scientific spectra.
%\item[extract.py] Script that extracts the scientific echelle spectra.
%\item[order\_trace.py] Script that searches for the flat orders in the CCD images.
\item[procedures.py] Contains all the procedures for the data analysis.
\item[tkcanvas.py] Contains the plotting routines to create the user interfaces (UI).
\item[plot\_img\_spec.py] This script controls plotting of CCD images, graphs, and the extracted spectra.
\item[remove\_orders.py] This needs to be run in order to find an initial wavelength solution (will be included in reduction\_day.py later).
%\item[ident\_arc.py] This needs to be run in order to find an initial wavelength solution (will be included in reduction\_day.py later).
\end{description}

When running the scripts for the first time, python will create a new file called \verb|<filename>.pyc| for some of the files. No harm will be done in removing or keeping the files.


\subsection{General information about the way the pipeline works}

%\noindent 
\subsubsection*{Handling parameters}

\begin{enumerate}
  \item The script has some hard coded values in the *.py files (normally at the beginning of a procedure). These values can be changed for testing, but usually do not need any changes.
  \item The pipeline reads the parameters from a configuration file (standard: \verb|conf.txt|, given in the python script). The parameters in the configuration file need adjustment on a regular basis (see Section~\ref{section:steps_new_data_set}).
  \item Furthermore, the pipeline reads the file given in parameter \verb|onfigfile_fitsfiles|, which is automatically created by the pipeline.
  \item The parameters which are set in the configuration file can be overwritten with a command line input when a python script is started (e.g. \verb|python bla.py argument1=valuex argument2=valuey|).
  \item Some parameters can be overwritten during the run time of the script by user input.
\end{enumerate}

\subsubsection*{Finding further information}

\begin{itemize}
  \item The pipeline logs the execution of procedures and necessary information in a logfile (standard: \verb|logfile|). This information is also printed into the terminal window.
  \item All adjustable parameters are logged at the beginning and at the end of the execution of a python script into a logfile (standard: \verb|logfile_params|).
  \item Images with the results of some steps can be found in a subfolder (standard: \verb|logging|). Some of these images are shown in Figures~\ref{figure_orders_in_master_flat}, \ref{figure_arcorders_in_master_arc}, \ref{figure_arc_line_identification_positions}, or \ref{figure_arc_line_identification_residuals}.
  \item Each parameter is explained in detail in the configuration file.
  \item The input and output parameters of the individual procedures are explained in the file \verb|procedures.py|.
\end{itemize}

\subsection{Short introduction to reduction of CCD images}

The data stored in CCD images is affected by the physical parameters of the individual pixels and way the readout electronics work. Therefore each scientific frame needs to be corrected (pixel by pixel) with the formula:
\begin{equation}
  \mathrm{reduced\ Science} = \frac{\mathrm{raw\ Science} - \mathrm{master\ Bias} - \mathrm{master\ Dark}}{\mathrm{master\ Flat}}\,.
\end{equation}
The master Dark should have the same exposure time as the Science frame and the master Flat should be normalised in order to keep the flux levels. To create the master Dark and master Flat, the following steps are necessary:
\begin{equation}
  \mathrm{master\ Dark} = \mathrm{raw\ Dark} - \mathrm{master\ Bias}
\end{equation}
\begin{equation}
  \mathrm{master\ Flat} = \mathrm{raw\ Flat} - \mathrm{master\ Bias} - \mathrm{master\ Dark}\,.
\end{equation}
The master Dark used for the creation of the master Flat should have the same exposure time as the Flat and needs to be corrected with the Bias. The master Bias in each of the formulas can be different.

In order to decrease the noise levels, each of the master file should be created by median combining several (corrected) images together. If the brightness of the individual flats vary, then the flats should be weighted by their median flux before combining them. Combining all steps leads to the formula
\begin{equation}
  \label{eq:reduction_full}
  \mathrm{reduced\ Science} = \frac{\mathrm{raw\ Science} - B_S - (D_S - B_{D_S})}{F - B_F - (D_F - B_{D_F})}\,,
\end{equation}
where $B_S$ is the master Bias, created by combining biases taken at a similar time as the science frame, $D_S$ is the master Dark, created of darks with the same exposure time as the science frame. In case the bias level and noise don't change during the night, then Equation~\ref{eq:reduction_full} changes to
\begin{equation}
  \mathrm{reduced\ Science} = \frac{\mathrm{raw\ Science} - D_S}{F - D_F}\,.
\end{equation}

In case the dark level is negligible and the Bias level is constant, then Equation~\ref{eq:reduction_full} changes to
\begin{equation}
  \mathrm{reduced\ Science} = \frac{\mathrm{raw\ Science} - B}{F - B}\,.
\end{equation}


In the pipeline always the individual frames are corrected before frames are combined.
% -------------------------------------------------------------------------------------------


\newpage
\section{Running the code on a new set of data (e.g. a new night)}
\label{Section:running_the_code}

\noindent The following steps will be performed on a new set of data:
\begin{itemize}
  \item[1.] Creating the following reduced and combined files:
  \begin{description}
    \item[sflat] File in which the science traces can be determined (standard: 5x white light flats, best without arc lamp). This file is also used in order to create a map of the background flux
    \item[arc] File in which the wavelength calibration traces can be determined (standard: 5x ThAr alone (future development: white light flats)).
    \item[arc\_l]: Long arc exposure to create a good wavelength solution over the whole chip (standard: 5x 60\,s ThAr).
    \item[arc\_s]: Short exposure in order to find the center of the saturated lines in arc\_l (standard: 5x 10\,s ThAr taken between the arc\_l images).
    \item[flatarc]: File which contains the flat in the science fiber and the arc in calibration fiber (standard: 5x files with the white light flats in science fiber and ThAr in the calibration fiber).
  \end{description}
  \item[2.] Determining the shift of the science traces compared to the previous solution (e.g. previous day). If the instrument was not touched, the shift should be small and constant ($\rightarrow$~Fig.~\ref{figure_orders_in_master_flat}). If the file for the previous solution does not exist, or if a big deviation to the previous solution has been found, then another step will be executed:
  \begin{itemize}
    \item[2a.] Finding the traces of all science orders.
  \end{itemize}
  \item[3.] Creating a map of the leaking light between the science orders (background map).
  \item[4.] Finding the traces of the calibration orders ($\rightarrow$~Fig.~\ref{figure_arcorders_in_master_arc}).
  \item[5.] Create the wavelength solution for the night ($\rightarrow$~Fig.~\ref{figure_arc_line_identification_positions} and \ref{figure_arc_line_identification_residuals}). This is based on the solution of the previous data set, which is adjusted according to the given parameters.
  \item[6.] Extract the flat and normalise it.
\end{itemize}

\noindent If the result file of any of the above steps already exist in the folder in which the code is run, then the existing file is read instead of performing the step again.

\subsection{Necessary CCD images}
To get the best results, the following data should be taken:
\begin{itemize}
  \item \textit{true Flat (at least 11 files of the evenly illuminated CCD)}. This has tested to improve the data quality when using a camera with small full well depth. The filename should contain \textbf{flat} for automatic processing.
  \item Flat (3x, white light source through the science fiber), called \textbf{sflat}. The calibration fiber should be dark for this data.
  \item Arc (5x, calibration lamp through the calibration fiber, alternating a short and a long exposure time). The filename should be \textbf{arc} and the science fiber should be dark for this data.
  \item FlatArc (11x, white light source and calibration lamp), called \textbf{flatarc}
  \item Bias (11x) and/or Darks (11x, for the exposure time of the true Flat and FlatArc)
\end{itemize}

\subsection{Steps to run the code on a new set of data}
\label{section:steps_new_data_set}
\noindent

\begin{enumerate}
  \item Create and enter a new folder. This folder will be used for the reduced and extracted data.
  \item Copy the configuration file (\verb|conf.txt|) into the folder. The following parameters might need to be changed in the file \verb|conf.txt|:
  \begin{description}
    \item[GUI] : If set to true, this allows manipulation of some parameters in a graphical user interface (GUI) during the runtime of the script.
    \item[raw\_data\_path] : Folder to the raw data.
    %\item*\_rawfiles] : Replace any filenames, which are different in the current observation
    %\item[*\_calibs\_create] : Change the calibration steps, which are applied to the raw files before combining them. A list of possible calibrations are given in Section~\ref{section:extraction}.
    \item[original\_master\_order\_filename] : Path to the traces of the science orders from the previous day. This file will be the base for finding the traces in the current night ([Step 2] as described in Section~\ref{Section:running_the_code}). Leave empty if the science orders should be searched without taking the previous solution into account (e.g. after the setup of the spectrograph has changed).
    \item[original\_master\_arc\_solution\_filename] : Path to the previous wavelength solution. This solution will be used as base for the wavelength solution in the current night. In case of a new setup see Section~\ref{section:create_new_wave_solution}.
    %In case of a new setup, it can be set to \verb|manual_solution.fits| (or any filename that doesn't exist). The script will then create a new solution from the information given in the file \verb|arc_lines_wavelength.txt|. For a description of the format of this file, check Section~\ref{section:create_new_wave_solution}.
  \end{description}
  \item Run the python script: \verb|python <path to scripts>/prepare_file_list.py|. See Section~\ref{Section:prepare_files} for more information
  \item Run the python script: \verb|python <path to scripts>/reduction_day.py|
\end{enumerate}

After checking the results (see Section~\ref{section:results_pipeline}), one might want to remove wrongly identified orders. This can be done in a graphical user interface by running \verb|remove_orders.py|. The old files will be moved into a sub-folder and the necessary steps of \verb|reduction_day.py| will run again.

\subsection{Assigning the observed data and calibration data to the pipeline}
\label{Section:prepare_files}

The script \verb|prepare_file_list.py| reads all files in the folder (and subfolders) given in parameter \verb|raw_data_path|. The file name and header information are used to determine the type of file and if it can be used for calibration. The header parameters are thereby defined by the following parameters in the configuration file:

\begin{description}
  \item[raw\_data\_imtyp\_keyword:] Header keyword if the image type (standard: \\ \mbox{IMAGETYP})
  \item[raw\_data\_imtyp\_bias:] Value of the for the header keyword \\ raw\_data\_imtyp\_keyword for bias frames (standard: Bias Frame)
  \item[raw\_data\_imtyp\_dark:] Value of the for raw\_data\_imtyp\_keyword for dark frames (standard: Dark Frame)
  \item[raw\_data\_imtyp\_flat:] Value of the for raw\_data\_imtyp\_keyword for flat frames (standard: Flat Frame)
  \item[raw\_data\_exptim\_keyword:] Header keyword for the exposure (standard: \\ \mbox{EXPTIME})
  \item[raw\_data\_dateobs\_keyword:] Header keyword observing date and time (in UTC). The format needs to be \mbox{YYYY-MM-DDTHH:MM:SS} (e.g. \\ \mbox{2018-02-28T23:34:01})  (standard: \mbox{DATE-OBS}).
\end{description}


The file type and definition of the fibers is done by using the filename. The assignment is done in the order given in Table~\ref{Tab:fiber_definition}. The result of this assignment is stored in a text file, which is shown to the user. The file can be edited (these information won't be overwritten if the script is re-executed). The following information is stored for each file in the raw data path (tab-separated):
\begin{table}
 \caption{Assignment of the fibers using the header keywords as given in the parameters of the configuration and filename. The science and calibration fibers are denoted with 'fiber1' and 'fiber2', respectively. Later assignment overwrites earlier ones. The filename is case-insensitive. -- means no change has been done.}
 \label{Tab:fiber_definition}
 \begin{tabular}{l l l}
 \small
 condition 															& fiber1 & fiber2 \\
 \hline
 filename contains \verb|bias|										& bias	& bias \\
 filename contains \verb|dark|										& dark	& dark \\
 filename contains \verb|flat| but not \verb|sflat| 				& flat	& flat \\
 \verb|raw_data_imtyp_keyword| equals \verb|raw_data_imtyp_flat| 	&       & \\
 \hspace{1cm} and filename dosn't contain \verb|sflat| 				& flat  & flat \\
 filename contains \verb|arc|						   				& -- 	& wave \\
 \verb|raw_data_imtyp_keyword| equals \verb|raw_data_imtyp_bias| 	& bias	& bias \\
 \verb|raw_data_imtyp_keyword| equals \verb|raw_data_imtyp_dark| 	& dark	& dark \\
 none of the above and the filname doesn't start with \verb|arc|  & science & --   \\
 \end{tabular}
\end{table}

\begin{itemize}
  \item Filename
  \item Type of light for the science fiber
  \item Type of light for the calibration fiber
  \item Exposure time in seconds
  \item Observation time
  \item Flag 'e', if the spectrum should be extracted. This can be modified in order to allow different processing of the images before extraction. The following options are possible:
    \begin{description}
      \item[e alone:] The processing as given in parameter \verb|extract_calibs_create_g| will be assigned.
      \item[e \textless obj \textgreater :] The processing as given in parameter \verb|extract<obj>_calibs_create_g| will be assigned. If this parameter doesn't exist, then parameter \verb|extract_calibs_create_g| will be used
      \item[ec \textless obj \textgreater :] The same as \textbf{e \textless obj \textgreater}, but instead of extracting each file induvidually, all files with \textbf{ec \textless obj \textgreater} will be combined into a file called \verb|master_<obj>.fits| and then this file is extracted.
      \item One raw file can be used for different extractions if several flags are combined with ',', e.g. \textit{e,ecSunAll,ecSunCentroid}.
    \end{description}
\end{itemize}


\subsection{Results from the pipeline}
\label{section:results_pipeline}

\noindent \textbf{Step 1:} The reduced and combined CCD images will be stored in the folder where the pipeline was run, if the parameter \verb|master_<type>_filename| exists. Thereby \verb|<type>| defines the image type, e.g. bias, sflat, or arc\_l.

\noindent \textbf{Step 2:} The trace of each scientific order is stored in the file given in parameter \verb|master_order_filename| (standard: \verb|master_orders.fits|). This file contains one line for each order, normally starting with the reddest order, which is located on the left side of the CCD image. Each line contains the following information:
\begin{itemize}
  \item Number of the order
  \item Parameters of a polynomial fit to the trace, e.g. 6 values if the trace is fitted with a polynom of order 6
  \item The lowest and highest pixel in dispersion axis, for which the trace can still be identified.
  \item The last three entries of each line define the width of the trace: the width from the center to the left, the width from the center to the right, and the Gaussian width.
\end{itemize}
 

\begin{figure} 
  \begin{center}
    \includegraphics[width=\textwidth]{./figures/orders_in_master_flat}
  \end{center} 
  \caption{Reduced CCD image of a white light flat (log10 gray scale) with the marked traces of the identified scientific orders (red). The extraction width is given in dashed lines.
    \label{figure_orders_in_master_flat}}
\end{figure}

\noindent \textbf{Step 3:} The background map, 2d image is stored in the file given in parameter \verb|background_image_filename| (standard: \verb|background.fits|). Additionally a mask which provides the pixel which are used to create the background map is stored in the file given in parameter \verb|background_px_filename| (standard: \verb|background_px.fits|).

\noindent \textbf{Step 4:} The traces of the orders of the calibration fiber are stored in the file given in parameter \verb|master_orderarc_filename| (standard: \verb|master_ordersarc.fits|). The format of the file is the same as for the scientific orders. The traces of the calibration orders are only shifted from the scientific orders while the curvature of the traces is kept the same.

\begin{figure} 
  \begin{center}
    \includegraphics[width=\textwidth]{./figures/arcorders_in_master_arc}
  \end{center} 
  \caption{Reduced CCD image of a ThAr exposure (log10 gray scale) with the marked traces of the identified calibration orders (red). The extraction width is given in dashed lines.
    \label{figure_arcorders_in_master_arc}}
\end{figure}



\noindent \textbf{Step 5:} The wavelength solution is stored in the file given in parameter \verb|master_arc_solution_filename| (standard: \verb|master_arc_solution.fits|). The parameters for each order are stored in one line. For each order the following values are stored:
\begin{itemize}
  \item Real order, as derived from the grating equation.
  \item Central pixel of the order.
  \item Parameters of a polynomial fit to the trace, e.g. 4 values if the dispersion axis is fitted with a polynom of order 4.
  \item List of the wavelengths of all the identified reference lines in this order.
\end{itemize}

During the step to find the wavelength solution, the pipeline logs data similar to the following output:
\begin{lstlisting}[style=base, basicstyle=\tiny]
Info: To match the most lines in the arc with the old wavelength solution, a shift
of -2 orders, a multiplier to the resolution of 0.994, a shift of -10 px, and a
shift of 0.0 px per order needs to be applied. 1046 lines were identified. The
deviation is 0.1197 Angstrom.
Info: used 524 lines. The standard deviation of the fit is 0.0054 Angstrom. A 2d
polynom fit with 4 orders along the traces and 4 orders perpendicular to the orders
was used. With this solution, the offset to real orders is 72. With this offset, the
standard deviation of the residuals between the central wavelengths and the grating
equation is 0.1295 Angstrom. Using the original solution gives an offset of 72.
order	cenwave	minwave	maxwave	ranwave	Ang/px	name	number	gausswi	gausswi	min_	max_	range_reflines
								dth_avg	dth_std	refline	efline	_whole_order

0	7978.6	7894.7	8054.2	159.5	0.038	Ar I  	2	1.78	0.58	7916.4	7948.2	98.1
0	7978.6	7894.7	8054.2	159.5	0.038	Th I  	2	2.04	1.15	7937.7	8014.5	98.1
...
27	5800.1	5769.1	5854.3	85.2	0.027	Ar I  	2	3.06	0.15	5802.1	5834.3	44.6
27	5800.1	5769.1	5854.3	85.2	0.027	Th I  	6	2.31	0.41	5789.6	5832.4	44.6
-1	-1.0	-1.0	-1.0	-1.0	-1.000	Ar I  	148	2.07	0.61	5802.1	7948.2	2146.1
-1	-1.0	-1.0	-1.0	-1.0	-1.000	Th I  	376	2.04	0.66	5789.6	8014.5	2224.9
\end{lstlisting} 
Thereby the table contains the following information:
\begin{description}
  \item[order] Order of the trace, starting with 0 for the reddest order ($\tilde{m}$). To get the real order the offset $m_0$ is given in the text before (here: 72). The offset is determined using two different ways. First the data is compared to the grating equation $\lambda \propto m_0 + \tilde{m}$. In Practical this was done by searching for the smallest slope in the formula $y = (m_0 + \tilde{m})\lambda_c$, were $\lambda_c$ is central wavelength of each order. The second value for the real order offset is determined from the shift towards the previous wavelength solution. Both values for the offset should be the same. Only the first value is saved in the file.
  \item[cenwave] Central wavelength of the order, determines the zero point of the wavelength solution.
  \item[minwave, maxwave, ranwave] Minimum and maximum wavelength, and wavelength range which is covered by the trace of this order.
  \item[Ang/px] Resolution in $\frac{\AA}{\mathrm{px}}$ at the central wavelength.
  \item[name] Type of the reference line. If different types of reference lines were found in the order then a output for each available type is created.
  \item[number] Number of reference line for this type and order.
  \item[gausswidth\_avg, gausswidth\_std] Average and standard deviation of the Gaussian width of the emission lines
  \item[min\_refline, max\_refline] Minumum and maximum wavelength of the reference lines of this type and order
  \item[range\_reflines\_whole\_order] Wavelength range which was covered by reference lines for this order (independent of type of the line)
\end{description}
The last lines give the information for all orders. Columns, for which no useful information can be derived show the value \verb|-1|.

\begin{figure} 
  \begin{center}
    \includegraphics[width=\textwidth]{./figures/arc_line_identification_positions}
  \end{center} 
  \caption{Reduced CCD image of a ThAr exposure (log10 gray scale) with the identified lines from the reference catalogue (red). Only this set of data was used to create the wavelength solution.
    \label{figure_arc_line_identification_positions}}
\end{figure}


\begin{figure} 
  \begin{center}
    \includegraphics[width=\textwidth]{./figures/arc_line_identification_residuals}
  \end{center} 
  \caption{Residuals between the identified cataloge lines and the wavelength solution. Colorcoded are the different orders.
    \label{figure_arc_line_identification_residuals}}
\end{figure}

\noindent \textbf{Step 6:} The normalised white light flat is stored in the file given in parameter \verb|master_flat_spec_norm_filename| (standard: \verb|master_flat_spec_norm.fits|). The extraction and data format is described in Section~\ref{section:extraction}

\subsection{Creating a new wavelength solution}
\label{section:create_new_wave_solution}
If no previous wavelength solution exist, then wavelengths and pixel need to correlated manually. In this case the parameter \verb|original_master_arc_solution_filename| needs to point to a file, which does not exist (e.g. \textit{master\_wavelength\_manual.fits}). Then the python scrip can be run normally. It will stop after searching for the lines in the emission line spectra. The order and pixel position of all identified lines are stored in the file given in parameter \verb|logging_found_arc_lines|. This file can be opened and the corresponding wavelengths can be added to some of the lines. I have found that providing 1.5 lines per order is enough for the pipeline to do the rest. The lines should cover as much of the CCD image as possible.

The correlated data needs to be saved into file \verb|arc_lines_wavelength.txt| with the following tab-separated entries:
\begin{itemize}
  \item Order (starting at 0)
  \item Real order (bigger than 0, usually between 60 and 120)
  \item Pixel
  \item Wavelength
  \item Type of the line (e.g. ThI, NeII).
\end{itemize}

Afterwards the script can run again and will use this data to create a new wavelength solution.

% -------------------------------------------------------------------------------------------


\newpage
\section{The Extraction of science data}
\label{section:extraction}


% -------------------------------------------------------------------------------------------

Once the preparation steps have been run for a new set of data (see Section \ref{Section:running_the_code}) the scientific data can be extracted. This is done with the python script \verb|extract.py|.

Before running the script the name of the files which should be extracted needs to be given. afterwards the script can be run using
\begin{lstlisting}[style=base]
python <path to script>/extract.py
\end{lstlisting}

The script will load all necessary files (created by the step above, see Section~\ref{Section:running_the_code}) and afterwards perform the following steps:
\begin{enumerate}
  \item Apply the corrections to the CCD image as given in parameter \verb|calibs|. The following options are possible:
  \begin{description}
    \item[subframe] Use only an area of the CCD image.
    \item[badpx\_mask] Apply the bad pixel mask, given in parameter \verb|badpx_mask_filename|.
    \item[bias] Apply a master bias, which will be created from the files given in the parameter \verb|bias_rawfiles| by using the settings given in the parameter \verb|bias_calibs_create|.
    \item[dark] Apply a master dark, which will be created from the files given in the parameter \verb|dark?.?_rawfiles| by using the settings given in the parameter \verb|dark?.?_calibs_create|. The \verb|?.?| stands for the exposure time of the science observation as found in its header. Alternatively, to force the use of a specific dark, the entry needs to consists of 'dark' with at least one additional character.
    \item[flat] Apply a master flat, which will be created from the files given in the parameter \verb|flat_rawfiles| by using the settings given in the parameter \verb|flat_calibs_create|.
    \item[background*] (standard: \verb|background_image_filename|) Applies background correction using the filename given in the parameter \verb|background*|. The background image will be scaled by the exposure time of the scientific image, before its subtracted from the scientific image.
  \end{description}
  \item Find the shift to the file containing the traces. Due to thermal movement the CCD might can move in respect to the instrument.
  \item Extract the science fiber spectrum (and error).
  \item Extract the calibration fiber spectrum.
  \item Find the shift to the wavelength solution. The identified lines from the reference catalogue are searched and fitted in the calibration fiber spectrum. Then the shift is calculated between the original and fitted position.
  \item Calculate the wavelength for each order and pixel by solving the shifted wavelength solution.
  \item Create the flat normalised spectrum (and error).
  \item Create the continuum corrected spectrum.
  \item Perform some general measurements which are stored in the header.
  \item Writing the file with all extracted data into the folder given in the parameter \verb|path_extraction| (standard: \verb|extracted|).
\end{enumerate}

\subsection{Format of the extracted files}

The final fits file contains the original header and some additional information, for example the calibration steps which were applied and some information about the flux collected in the different orders. The data in the file is stored in a 3D array in the form: data type, order, and pixel. The data types are similar to the ones created by the CERES pipeline and are the following:
\begin{enumerate}
  \setcounter{enumi}{-1}
  \item 2D array with the wavelength for each order and pixel.
  \item Extracted spectrum without any modification.
  \item (Measurement of the error the extracted spectrum)
  \item Flat corrected spectrum, calculated by dividing the extracted spectrum and the normalised flat spectrum.
  \item (Error the flat corrected spectrum)
  \item Continuum normalised spectrum. The continuum is derived by fitting a polynomial to the flat corrected spectrum, using only areas of the spectrum where no lines are located. 
  \item Signal to noise ratio in the continuum, calculated from the residuals between continuum fit and measured continuum and the flux in the continuum.
  \item Mask with good areas of the spectrum. The following values are used:
  \begin{itemize}
    \item[1] good
    \item[0] no data available
    \item[0.1] saturated pixel in the extracted spectrum
    \item[0.2] bad pixel in the extracted spectrum
  \end{itemize}
  \item Spectrum of the calibration fiber, e.g. of the emission line lamp.
\end{enumerate}


% -------------------------------------------------------------------------------------------


\newpage
\section{Post-extraction analysis}

% -------------------------------------------------------------------------------------------
\noindent Once the science spectra were extracted these files can be analysed more in detail. 

\subsection{Plotting the data}

To plot the results the python program \verb|plot_img_spec.py| can be used. This script read the files given in the file \verb|plot_files.lst| and will plot at the beginning all data. Further limitations of the plotted data can be done using the UI. For a plot in wavelength axis the first text box need to contain a \textbf{'w'}. For plotting only data from a subsection of files, the first text boxes 'Exclude orders/frames' and 'Exclude' need to be used. For plotting only a subsection of data types the second text boxes with 'Exclude orders/frames' and 'Exclude' are used to define this. For plotting only some orders, the last text boxes are used (see an example in Fig.~\ref{figure_plotting_results_example}).

\begin{figure} 
  \begin{center}
    \includegraphics[width=\textwidth]{./figures/screenshot_plot_img_spec}
  \end{center} 
  \caption{An example of how to plot the extracted data. Shown are the solar spectra of entry 0 and 14 in the plot\_files.lst file. The graph shows the continuum normalised flux (data type 5), plotted over the wavelength (w). Only orders 14 and 16 are shown.
    \label{figure_plotting_results_example}}
\end{figure}


\subsection{Finding the radial velocity }

\noindent The radial velocity measurement is based on the \textit{CERES} pipeline. Thereby a template is cross correlated with the scientific spectrum. For the analysis the following steps need to be run:
\begin{lstlisting}[style=base]
ls extracted/*.fits > analysis_files.lst
python <path to script>/find_rv.py | tee RV_logfile
\end{lstlisting}



\section{Extracting HARPS data}

\subsection{Getting the data}
Search and download the data from \url{http://archive.eso.org/eso/eso_archive_main.html}. For example data select night '2015 07 30' and check only 'HARPS/LaSilla'.

The reduced data can be found at: \url{http://archive.eso.org/wdb/wdb/eso/repro/form}. For example data select night '30 07 2015'.

The raw data (*fits.Z) can be extracted with
\begin{lstlisting}[style=base]
gunzip *
cat <<EOT > extract_red_chip.py
#!/usr/bin/python
# -*- coding: utf-8 -*-
import os
from astropy.io import fits

os.system('mkdir -p red_chip')
for entry in os.popen('ls -1 *.fits').readlines():
    im = fits.getdata(entry[:-1],2)
    im_head = fits.getheader(entry[:-1],2)
    fits.writeto('red_chip/'+entry[:-1], im, im_head, clobber=True)
EOT
python extract_red_chip.py
\end{lstlisting}


The reduced data (*.tar) can be extracted using
\begin{lstlisting}[style=base]
cat *.tar | tar -xvf - -i
\end{lstlisting}

\subsection{Preparing for data extraction}

The following replacements are necessary in the conf.txt file:
\begin{itemize}
  \item \verb|subframe  = [4096,2048,0,50]|
  \item \verb|rotate_frame = 180|
  \item \verb|bin_search_orders = 20,2|
  \item \verb|arcshift_range  = [-12, -20]| (red chip),\\ \verb|arcshift_range  = [-12, -20]| (blue chip
  \item \verb|bias_calibs_create      = [subframe]|
  \item \verb|bias_rawfiles           = HARPS.2015-07-30T19:57:17.883.fits|\\ (Header: \verb|OBJECT  = 'BIAS,BIAS'|)
  \item \verb|sflat_calibs_create     = subframe, bias|
  \item \verb|sflat_rawfiles          = HARPS.2015-07-30T19:58:10.417.fits|\\ (Header: \verb|OBJECT  = 'LAMP,DARK,TUN'|)
  \item \verb|arc_calibs_create = subframe, bias|
  \item \verb|arc_rawfiles = HARPS.2015-07-30T23:33:11.406.fits|\\ (Header: \verb|OBJECT  = 'WAVE,WAVE,THAR2'|)
  \item \verb|arc_l_calibs_create = subframe, bias|
  \item \verb|arc_l_rawfiles = HARPS.2015-07-30T23:33:11.406.fits, HARPS.2015-07-30T23:51:34.374.fits|\\ (Header: \verb|OBJECT  = 'WAVE,WAVE,THAR2'|)
  \item \verb|arc_s_calibs_create = subframe, bias|
  \item \verb|arc_s_rawfiles = HARPS.2015-07-30T23:51:34.374.fits|\\ (Header: \verb|OBJECT  = 'WAVE,WAVE,THAR2'|)
  \item \verb|arcflat_calibs_create = subframe, bias|
  \item \verb|arcflat_rawfiles = HARPS.2015-07-30T20:00:05.103.fits, HARPS.2015-07-30T20:00:44.455.fits, HARPS.2015-07-30T20:01:23.528.fits, HARPS.2015-07-30T20:02:02.441.fits, HARPS.2015-07-30T20:02:41.743.fits|\\ (Header: \verb|OBJECT  = 'LAMP,LAMP,TUN'|)
  \item \verb|original_master_arc_solution_filename = master_arc_solution_first.fits|. The file \verb|arc_lines_wavelength.txt| needs to be created (Section~\ref{section:create_new_wave_solution}).
  \item \verb|arc_lines_catalog = /home/ronny/Scripts/exohspec/reference_lines_ThAr-HARPS_Ceres.txt|
  \item \verb|use_catalog_lines = NeI, UI, ThI, ArI, ?, NoID, ArII, ThII|
\end{itemize}

Afterwards, all scripts can run as described above.





\appendix

\section{Module dependencies if not using Anaconda}
\label{section:module_dependency}
\noindent This program relies on the following modules in python 2.7

\begin{itemize}\itemsep0em
\item numpy
\item os
\item sys
\item time
\item datetime
\item operator
\item copy
\item random
\item warnings
\item tqdm
\item pickle
\item json
\item astropy
\item scipy
\item matplotlib
\item[] {\bf if python2:}
\item Tkinter
\item collections
\item[] {\bf if python3:}
\item tkinter
%\item numpy (1.11.2)
%\item astropy (1.1.2)
%\item matplotlib (1.5.1)
%\item tqdm (4.4.0)
%\item skimage (0.12.3)
\end{itemize}

% Other versions may work but these are the ones tested.

\end{document}



\begin{lstlisting}[style=base]

\end{lstlisting}