\documentclass[10pt,a4paper]{article}

\usepackage{listings}              % Only used for this template to display code, can delete
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}    %Driver-independent color extensions
\usepackage[linktocpage=true]{hyperref}            % Extensive support for hypertext in LaTeX
\usepackage{graphicx}              % Enhanced support for graphics
\usepackage{amsmath}

\newcommand\tab[1][1cm]{\hspace*{#1}}

\hypersetup{
    pdfauthor={Ronny Errmann, Neil Cook},
    pdfcreator={Ronny Errmann, Neil Cook},
    pdftitle={EXOhSPEC Data Reduction User Manual},
    pdfsubject={EXOhSPEC Data Reduction User Manual},
    pdfkeywords={EXOhSPEC, Data Reduction, User Manual},
    colorlinks=true,         % false: boxed links; true: colored links
    linkcolor=blue,          % color of internal links (change box color with linkbordercolor)
    citecolor=Maroon,        % color of links to bibliography
    filecolor=blue,          % color of file links
    urlcolor=blue,           % color of external links
    plainpages=false,       
}

% This is only used if you want to add code
\lstdefinestyle{base}{
  basicstyle=\small\ttfamily,
  backgroundcolor=\color{Tan},
  language=[LaTeX]{TeX},
  moredelim=**[is][\color{red}]{@}{@},
}

\title{User Manual for Data Reduction of the EXOhSPEC Instrument \\ Working version: v0.4.1}
\date{April, 2019}
\author{Ronny Errmann, Neil Cook\\ Physics, Astronomy and Maths, University of Hertfordshire}

\begin{document}

\maketitle

\pagenumbering{Roman}
\tableofcontents
\pagenumbering{arabic}

% -------------------------------------------------------------------------------------------

\section{Changelog}
\subsection*{v0.3.3}
\begin{itemize}\setlength\itemsep{0em}
 \item Added parameter \verb|raw_data_timezone_cor| to conf.txt.
\end{itemize}

\subsection*{v0.3.4}
\begin{itemize}\setlength\itemsep{0em}
 \item Added parameter \verb|object_file| to conf.txt.
 \item More information are stored in the header of the different output files.
 \item Barycentric velocity calculation and barycentric JD were improved/added.
 \item \verb|extraction_width_multiplier = 1|, \verb|arcextraction_width_multiplier = 1| \verb|width_percentile = 05|, and \verb|extracted_bitpix = -32| are standard now.
\end{itemize}

\subsection*{v0.4.0}
\begin{itemize}\setlength\itemsep{0em}
  \item Included the comparison between the wavelength solutions in science and calibration fiber.
  \item Improved radial velocity analysis using Terra.
  \item Renamed \verb|arc_l| and \verb|arc_s| into \verb|cal2_l| and \verb|cal2_s|.
  \item Better way of getting the object name from the filename.
  \item Added parameter \verb|path_ceres| to conf.txt.
  \item Added parameter \verb|terra_jar_file| to conf.txt.
  \item Renamed parameter \verb|path_rv| to \verb|path_rv_ceres|.
  \item Renamed parameter \verb|csv_path| to \verb|path_csv_terra|.
  \item General bug fixing.
\end{itemize}

\subsection*{v0.4.1}
\begin{itemize}
  \item Switched to barycentric correction (radial velocity and BJDTDB) from \url{https://github.com/shbhuk/barycorrpy}.
\end{itemize}
% ------------------------------------------------------------------------------
\newpage

\section{Introduction}
\label{intro}



% -------------------------------------------------------------------------------------------

This program is designed to take a fits image file (i.e. a CCD image) and run data reduction steps, extract out orders from an Echelle spectrograph (regardless of separation and curvature, as long as orders are distinguishable from one-another), apply the wavelength correction, measure the radial velocity, and perform further calibration steps. 

% -------------------------------------------------------------------------------------------


\newpage
\section{Installation and dependencies}
\label{installation}

\noindent This program was written to work with modules installed in Anaconda 2 and python 2.7. It is recommended to use an installation of anaconda 2 to use this program (If this is not possible, the whole module dependency is given in Appendix~\ref{section:module_dependency}).

%Similar to the CERES pipeline, the SSEphem package (\url{http://www.cv.nrao.edu/~rfisher/Python/py_solar_system.html}) in connection with the SOFA (\url{http://www.iausofa.org/}) functions are used. 

% -------------------------------------------------------------------------------------------

\subsection{With Anaconda and python 2.7}

\noindent Anaconda can be downloaded from \url{https://www.anaconda.com/download/}. Please select the version for python 2.7. After download it can be installed by running
\begin{lstlisting}[style=base]
sh Downloads/Anaconda2-5.0.1-Linux-x86_64.sh
\end{lstlisting}
(no superuser permissions are needed, the version might need to be changed).

After the installation and opening a new terminal, python should point to the one in the Anaconda installation. It can be checked by running \verb|which python|~. If the result doesn't point to your Anaconda installation, but somewhere else (e.g. \verb|/usr/bin/python|), an extra entry into \verb|.bashrc| or \verb|.tcshrc| needs to be added. If you use \verb|bash| add the following line (replace \textit{/home/exohspec} by the path you used for the installation to your \verb|.bashrc|. %, \textit{/home/\textless username\textgreater} is the standard installation path)
\begin{lstlisting}[style=base]
export PATH="/home/exohspec/anaconda2/bin:$PATH"
\end{lstlisting}
If you use \verb|csh| add the following line (replace \textit{/home/exohspec} by the path you used for the installation to your \verb|.tcshrc|
\begin{lstlisting}[style=base]
setenv PATH /home/exohspec/anaconda2/bin\:$PATH
\end{lstlisting}

After making the change and opening a new terminal, python should point to the file in the Anaconda installation (\verb|which python|).

\subsubsection{Additional modules}

\noindent Once Anaconda is installed tow other modules are needed (tqdm, gatspy). If Anaconda is installed correctly then pip can be used to install this module
\begin{lstlisting}[style=base]
pip install tqdm
pip install gatspy
pip install barycorrpy
pip install ephem
\end{lstlisting}
%gatspy for lomb scargle
% For BJD (but not needed anymore):
%pip install jplephem
%pip install de423

\subsubsection{Manual installation of barycorrpy }
In case \textit{barycorrpy} is not available using \textit{pip}, please install it by using the instruction of the package: \url{https://github.com/shbhuk/barycorrpy/wiki/1.-Installation}
Afterwards, please make sure that \verb|import barycorrpy| works in python.

\subsubsection{Install pyfits for radial velocity analysis}
To use the cross-correlation based radial velocity from the CERES pipeline (see Section~\ref{Section:Explanation_CERES_pipeline}) the package pyfits is necessary:
\begin{lstlisting}[style=base]
conda install gsl=2.2.1
pip install pyfits
\end{lstlisting}

If the installation of pyfits fails, the following two commands can be tried to install it under conda:
\begin{lstlisting}[style=base]
conda install -c cefca pyfits
conda install -c sherpa pyfits
\end{lstlisting}
This might downgrade numpy, which will cause problems. Therefore, after installing pyfits, numpy needs to be upgraded again:
\begin{lstlisting}[style=base]
pip install numpy --upgrade
\end{lstlisting}

Updating anaconda might also solve it:
\begin{lstlisting}[style=base]
conda update --prefix /home/exohspec/anaconda2 anaconda
\end{lstlisting}

\subsection{Necessary files}

\noindent The Necessary python and configuration files can be loaded from github (adjust the version to the latest version by checking \url{https://github.com/ronnyerrmann/exohspec/releases}):
\begin{lstlisting}[style=base]
wget https://github.com/ronnyerrmann/exohspec/archive/v0.4.0.tar.gz
tar -xzvf v*.tar.gz
\end{lstlisting}

\noindent The following files should be available now in the program folder:
\begin{description}
 \item[prepare\_file\_list.py] Script to automatically assign the fits files into the corresponding calibration steps.
 \item[reduction\_day.py] Script which needs to be run on each new set of data. It creates the data, which is necessary in order to extract the scientific spectra. Afterwards it extracts the Echelle spectra of the science images.
%\item[extract.py] Script that extracts the scientific echelle spectra.
%\item[order\_trace.py] Script that searches for the flat orders in the CCD images.
 \item[procedures.py] Contains all the procedures for the data analysis.
%%%\item[find\_rv.py] Script that performs the radial velocity analysis.
 \item[tkcanvas.py] Contains the plotting routines to create the user interfaces (UI).
 \item[plot\_img\_spec.py] This script controls plotting of CCD images, graphs, and the extracted spectra.
 \item[remove\_orders.py] If the automatic process identified wrong orders, then this script allows the user to remove them using a GUI.
 \item[create\_badpx\_mask.py] Script to create a bad pixel mask (in testing).
% \item[SSEphem] Necessary folder to calculate barycentric velocity. \textit{(It might be necessary to install the package to have the correct paths.)} 
% \item[ssephem\_update.py] Script to update the SSEphem package (See Chapter~\ref{Section:update_ssephem}).
\end{description}

When running the scripts for the first time, python will create a new file called \verb|<filename>.pyc| for some of the files (compiled script). No harm will be done in removing or keeping the files.

\subsection{External packages for Radial velocity analysis (optional)}
The pipeline creates extracted spectra in different formats, which then can be further analysed using available software. Additionally the pipeline can use available packages to find the radial velocity of the object. Below are described the requirements of the external software.

\subsubsection{Ceres Pipeline}
\label{Section:Explanation_CERES_pipeline}
Authors: Rafael Brahm, Andr{\'e}s Jord{\'a}n, N{\'e}stor Espinoza. If you make use of the Radial Velocity analysis from the Ceres , please cite Brahm et al. 2017\footnote{\url{https://ui.adsabs.harvard.edu/\#abs/2017PASP..129c4002B/abstract}}.

The Package can be downloaded from\\ \url{https://github.com/rabrahm/ceres} (``Clone or Download''-button)\\ and then unpack the archive. To make it work, please follow the Installation Chapter in the README.md file on\\ \url{https://github.com/rabrahm/ceres} .


\subsubsection{Terra}
Terra can be downloaded from\\ \url{https://drive.google.com/file/d/1xK-lYghFwpwtdXG9b4IbryYRd102q7So/view} . It only has to be extracted. To check that all dependencies are installed on the system one can run.
\begin{lstlisting}[style=base]
java -jar <path to terra>/terra/PRV.jar
\end{lstlisting}
This should produce the entry \textit{*** TERRA v1.8 ***} before failing.

\subsection{General information about the way the pipeline works}

%\noindent 
\subsubsection{Handling parameters}

\begin{enumerate}
  \item The script has some hard coded values in the *.py files (normally at the beginning of a procedure). These values can be changed for testing, but usually do not need any changes.
  \item The pipeline reads the parameters from a configuration file (standard: \verb|conf.txt|), given at the beginning of the python scripts. Some of the parameters in the configuration file need adjustment on a regular basis (see Chapter~\ref{Section:steps_new_data_set}).
  \item Furthermore, the pipeline reads the configuration file given in parameter \verb|configfile_fitsfiles| (standard: \verb|fits_conf.txt|), which is automatically created by the pipeline when running \verb|prepare_file_list.py|.
  \item The parameters which are set in the configuration file(s) can be overwritten with a command line input when a python script is started (e.g. \verb|python bla.py argument1=valueX argument2=valueY|).
  \item Some parameters can be overwritten during the run time of the script by user input if the GUI is enabled.
\end{enumerate}

\subsubsection{Finding further information}

\begin{itemize}
  \item The pipeline logs the execution of procedures and necessary information in a logfile (standard: \verb|logfile|). Most of this information is also printed into the terminal window. In the logfile, each entry will start similar to 
  \begin{lstlisting}[style=base]
20190225160303 - 37448 - 
  \end{lstlisting}
  and decodes the current time (YYYYMMDDHHMMSS) of the entry and the PID\footnote{process ID: \url{https://en.wikipedia.org/wiki/Process_identifier}} of the process that created it.
  \item All adjustable parameters are logged at the beginning and at the end of the execution of a python script into a logfile (standard: \verb|logfile_params|) in the a json\footnote{\url{https://en.wikipedia.org/wiki/JSON\#Example}} format.
  \item Images with the results of some steps can be found in a logging subfolder (standard: \verb|logging|). Some of these images are shown in Figures~\ref{figure_apertures_in_master_flat} to \ref{figure_arc_line_identification_residuals}.
  \item Each parameter is explained in detail in the configuration file.
  \item The input and output parameters of the individual procedures are explained in the file \verb|procedures.py|.
\end{itemize}



% -------------------------------------------------------------------------------------------


\newpage
\section{Running the code on a new set of data (e.g. a new night)}


\subsection{Steps performed by the pipeline}
\label{Section:pipeline_steps_general}

\noindent The following steps will be performed on a new set of data:
\begin{itemize}
  \item[1.] Creating the following reduced and combined files:
  \begin{description}
    \item[trace1] File in which the science traces can be determined (standard: 5x white light flats, best without arc lamp). This file is also used to create a map of the background flux.
    \item[trace2] File in which the wavelength calibration traces can be determined (standard: 5x ThAr alone (future development: white light flats)).
    \item[cal2\_l]: Long emission lamp exposure to create a good wavelength solution over the whole chip for the calibration fiber (standard: 5x 100\,s ThAr or UNe).
    \item[cal2\_s]: Short exposure in order to find the center of the saturated lines in cal2\_l (standard: 5x 10\,s ThAr or UNe taken between the cal2\_l images).
    \item[(cal1\_l, cal1\_s)]: emission lamp spectra to create a wavelength solution for the science fiber (if applicable)
    \item[flatarc]: File which contains the blaze correction in the science fiber (standard: 5x files with the white light flats in science fiber).
  \end{description}
  \item[2.] Determining the shift of the science traces compared to the previous solution (e.g. previous day). If the instrument was not touched, the shift should be small and constant ($\rightarrow$~Fig.~\ref{figure_apertures_in_master_flat}). If the file for the previous solution does not exist, or if a big deviation to the previous solution has been found, then another step will be executed:
  \begin{itemize}
    \item[2a.] Finding the traces of all science orders. First in a heavily binned image (e.g. 20,5) to find the traces, and then in a slightly binned image (only few pixel in dispersion direction) where the position is redefined.
  \end{itemize}
% not useful  \item[3.] Creating a map of the leaking light between the science orders (background map).
  \item[3.] (for bifurcated fiber spectrographs) Finding the traces of the calibration orders by searching for the shift between each order in the trace1 and trace2 file ($\rightarrow$~Fig.~\ref{figure_arcapertures_in_master_arc}). 
  \item[4.] Create the wavelength solution for the night on the calibration fiber spectra (and maybe the science fiber spectra). ($\rightarrow$~Fig.~\ref{figure_arc_line_identification_positions} and \ref{figure_arc_line_identification_residuals}). This is based on the solution of the previous data set, which is adjusted according to the given parameters (see Chapter:~\ref{Section:steps_new_data_set}).
  \item[5.] Extract the flat and normalise it. This is used for the blaze correction.
  \item[6a.] (for single fiber spectrographs) Measure the instrumental drift in emission line spectra to calibrate the wavelength solution.
  \item[6b.] (if applicable: find the radial velocity drift between the wavelength solutions of calibration and science fiber)
  \item[7.] Extract the science spectra. This includes the following steps for each image:
  \begin{itemize}
    \item[a)] Data reduction of the CCD frame (if set up).
    \item[b)] Finding the shift between this frame and the \textbf{sflat} file.
    \item[c)] Extraction of the apertures for the science fiber.
    \item[d)] (for bifurcated fiber spectrographs) Extraction of the apertures for the calibration fiber.
    \item[e)] Finding the shift between the emission lines in the calibration spectra and the lines used for the wavelength solution (for bifurcated fiber spectrographs) or interpolating the measured drift from step 6. Calculating the wavelength for each pixel in the extracted spectrum.
    \item[f)] Creating the flat corrected spectrum.
    \item[g)] Creating the spectrum with normalised continuum.
    \item[h)] (Optional) Perform the radial velocity analysis (cross-correlation with template spectrum).
    \item[i)] Perform some general measurements which are stored in the header.
    \item[j)] Write the file with all extracted data into the folder given in the parameter \verb|path_extraction| (standard: \textit{extracted}).
    \item[k)] Write subsets of data into different files to create compatibility with other software.
  \end{itemize}
  \item[8.] (Optional) Perform the radial velocity analysis by building a template spectrum from the observation.
\end{itemize}

\noindent If the result file of any of the above steps already exist in the folder in which the code is run, then the existing file is read instead of performing the step again in order to safe computational time. If a step needs to run again, the according result file needs to be deleted. (Further information can be found in Chapter~\ref{Section:Problem_solution}.)

\subsection{Necessary CCD images}
To get the best results, the following data (or more files) should be taken. Please note that all filenames are case-insensitive. \textbf{No spaces or commas are allowed in the file names.}
\begin{itemize}
  \item \textit{true Flat (at least 11 files of the evenly illuminated CCD)}. This has tested to improve the data quality when using a camera with small full well depth. The filename should contain \textbf{rflat} for automatic processing.
  \item Flat (11x, white light source through the science fiber), with the filename containing \textbf{sflat}, \textbf{tung}, or \textbf{whli}. The calibration fiber should be dark for this data.
  \item Arc (5x, calibration lamp through the calibration fiber, alternating a short (e.g. 5\,s) and a long (e.g. 120\,s) exposure time). The filename should start with \textbf{arc}, \textbf{ThAr}, \textbf{Th\_Ar}, or \textbf{UNe}. Results might be better, if the science fiber is dark.
  \item (\textit{Only necessary, if the shift in dispersion direction between the fibers of a bifurcated fiber should be measured}): Arc2 (5x, calibration lamp through the science fiber, alternating a short (e.g. 5\,s) and a long (e.g. 120\,s) exposure time). The filename should start with \textbf{arc2}, \textbf{ThAr2}, \textbf{Th\_Ar2}, or \textbf{UNe2}.
%  \item FlatArc (11x, white light source and calibration lamp), the filename should be \textbf{flatarc}, \textbf{sflatThAr}, \textbf{whli-UNe}, or similar.
  \item Bias (11x) and/or Darks (11x, for the exposure time of the true Flat and Flat)% and FlatArc)
  \item Science images: It is best to start the filename with the object name (as in reference file given by parameter \verb|object_file|, see Chapter~\ref{Section:create_object_list_file}). However, in order to try to match the object name with entries in the \verb|object_file| the parts of the filename containing ``\_'' and ``-'' are stripped away one by one from the end of the filename.
\end{itemize}

\subsection{Steps to run the code on a new set of data}
\label{Section:steps_new_data_set}
\noindent The following steps give an overview about the parameters which need to be adjusted when copying the configuration file from one night to the next.

\begin{enumerate}
  \item Create and enter a new folder. This folder will be used for the reduced and extracted data.
  \item Copy the configuration file (\verb|conf.txt|) into the folder. The following parameters might need to be changed in the file \verb|conf.txt|:
  \begin{description}
    \item[GUI] : If set to true, this allows manipulation of some parameters in a graphical user interface (GUI) during the runtime of the script. (not tested recently)
    \item[raw\_data\_path] : Folder to the raw data.
    %\item*\_rawfiles] : Replace any filenames, which are different in the current observation
    %\item[*\_calibs\_create] : Change the calibration steps, which are applied to the raw files before combining them. A list of possible calibrations are given in Chapter~\ref{section:extraction}.
    \item[original\_master\_traces\_filename] : Path to the traces of the science orders from the previous day. This file will be the base for finding the traces in the current night ([Step 2] as described in Chapter~\ref{Section:pipeline_steps_general}). Leave empty if the science orders should be searched without taking the previous solution into account (e.g. after the setup of the spectrograph has changed slightly). In this case the following parameters should be modified:
    \begin{description}\setlength\itemsep{0em}
      \item[order\_offset] It could be that not all or more echelle orders (especially on the red end) will be identified compared to the orders of the night, to which parameter \verb|original_master_wavelensolution_filename| is pointing. The parameter \verb|order_offset| gives the expected range of extra or fewer orders on the red side of the shift.
      \item[px\_offset] If the setup is touched, the whole spectrum could be moved along the detector in dispersion direction, compared to the previous solution (given in parameter \verb|original_master_wavelensolution_filename|). The parameter \verb|px_offset| gives the expected range and step size of the pixel-shift.
      \item[px\_offset\_order] Gives the range and step size of a shift per order between the individual orders (e.g. the spectrum is tilted compared to the CCD alignment).
      \item[resolution\_offset\_pct] Gives the expected change of resolution in percent between the current setup and the previous wavelength solution. The pipeline will test 11 resolutions between 0\% and the value given in parameter \verb|resolution_offset_pct|.
    \end{description}
    
    \item[original\_master\_wavelensolution\_filename] : Path to the previous wavelength solution. This solution will be used as base for the wavelength solution in the current night. In case of a new setup see Chapter~\ref{section:create_new_wave_solution}. In case no wavelength solution is required, set it to \verb|pseudo|.
    \item[\textless type\textgreater\_calibs\_create\_g] : Change the calibrations, which are applied to the CCD images before further processing or extraction for the different file types (e.g. bias, dark, flat, sflat, arc, flatarc, extract, wavelengthcal). A list of possible calibration options is given in Chapter~\ref{Section:parameters_CCD_proc} below.
    %In case of a new setup, it can be set to \verb|manual_solution.fits| (or any filename that doesn't exist). The script will then create a new solution from the information given in the file \verb|arc_lines_wavelength.txt|. For a description of the format of this file, check Chapter~\ref{section:create_new_wave_solution}.
  \end{description}
  \item Run the python script: \\ \verb|python <path to scripts>/prepare_file_list.py| . \\ See Chapter~\ref{Section:prepare_files} below for more information.
  \item Run the python script: \\ \verb|python <path to scripts>/reduction_day.py| .
  \item Check the out in the \verb|logfile|, the images in the logging path, or in results in the extracted files.
\end{enumerate}

\noindent After checking the results (see Chapter~\ref{section:results_pipeline}), one might want to remove wrongly identified apertures. If a trace is located close to the borders this can lead to wrongly traced orders, which can't be handled by the code automatically due to it's big flexibility. The orders can be removed in a graphical user interface by running \verb|remove_orders.py|. The old files will be moved into a sub-folder and the depending steps of \verb|reduction_day.py| will run again.

\subsection{Possible parameters for the CCD processing}
\label{Section:parameters_CCD_proc}
\noindent The list below shows all standard CCD calibration options available in the pipeline. The corrections are done on a pixel-by-pixel basis. The steps will be executed in the same order as given here.
\begin{description}
  \item[subframe] : The subframe as given in the parameter \verb|subframe| will be applied, only a section of the CCD will be used.
  \item[badpx\_mask] : Apply the bad pixel mask, given in parameter \verb|badpx_mask_filename|. If the file doesn't exist, all pixels are assumed to be good.
  \item[bias] : Apply a master bias, which will be created from the files given in the parameter \verb|bias_rawfiles| by using the settings given in the parameter \verb|bias_calibs_create|. These two parameters are created automatically by the script \verb|prepare_file_list.py| if bias frames exist in the raw data path.
  \item[dark] : Apply a master dark. A dark with the same exposure time as read from the fits header will be applied. The necessary parameters are created automatically by the script \verb|prepare_file_list.py|.
  \item[rflat] : Apply a master true flat. The necessary parameters are created automatically by the script \verb|prepare_file_list.py|.
%  \item[background] : Applies background correction using the filename given in the parameter \verb|background_filename|.The background image will be scaled by the exposure time of the scientific image, before its subtracted from the scientific image.
  \item[localbackground] : Applies background correction by fitting a 2d polynomalial against the current reduced image, excluding the area of the science and calibration traces. The fitted 2d-image is then subtracted from the (reduced) image.
\end{description}

\noindent The following parameters change the way, several CCD images are combined. In the pipeline always the individual frames are corrected before frames are combined.
\begin{description}
  \item[normalise] : Before combining the files the images are normalised by their median flux.
  \item[combine\_sum] : Normally, files are combined using a pixel by pixel median. With this keyword the files will summed up. This parameter will be overwritten by \verb|combine_mean|. When summing up several images, the value of pixels might extend \verb|max_good_value|.
  \item[combine\_mean] : Normally, files are combined using a median. With this keyword a pixel by pixel average will be used.
  %\item[] : 
\end{description}

\noindent The calibration options can be altered, as long as they contain the unique string in the option name. For example an option \verb|subframe_1| can be used, in this case the parameter \verb|subframe_1| needs to be defined in one of the calibration files. If a different bias, dark, or flat should be used, the following parameters need to be included in one of the configuration files (for the example of \textit{darkfixed}):
\begin{itemize}\setlength\itemsep{0em}
  \item \verb|darkfixed_rawfiles|
  \item \verb|darkfixed_calibs_create|
  \item \verb|master_darkfixed_filename|.
\end{itemize}


\subsection{Assigning the observed data and calibration data to the pipeline}
\label{Section:prepare_files}

The script \verb|prepare_file_list.py| reads all files in the folder (and subfolders) given in parameter \verb|raw_data_path|. The file name and header information are used to determine the type of file and if it can be used for calibration. The header parameters are thereby defined by the following parameters in the configuration file:

\begin{description}
  \item[raw\_data\_imtyp\_keyword:] Header keyword if the image type (standard: \\ \mbox{IMAGETYP}),
  \item[raw\_data\_imtyp\_bias:] Value of the for the header keyword \\ raw\_data\_imtyp\_keyword for bias frames (standard: Bias Frame),
  \item[raw\_data\_imtyp\_dark:] Value of the for raw\_data\_imtyp\_keyword for dark frames (standard: Dark Frame),
  \item[raw\_data\_imtyp\_flat:] Value of the for raw\_data\_imtyp\_keyword for flat frames (standard: Flat Frame),
  \item[raw\_data\_imtyp\_trace1:] Value of the for raw\_data\_imtyp\_keyword for frames to trace the science orders (for HARPS: LAMP,DARK,TUN),
  \item[raw\_data\_imtyp\_flatarc:] Value of the for raw\_data\_imtyp\_keyword for frames with the blaze function (for HARPS: LAMP,LAMP,TUN),
  \item[raw\_data\_imtyp\_trace2:] Value of the for raw\_data\_imtyp\_keyword for frames to trace the calibration orders (for HARPS: WAVE,WAVE,THAR2),
  \item[raw\_data\_exptim\_keyword:] Header keyword for the exposure (standard: \\ \mbox{EXPTIME}),
  \item[raw\_data\_dateobs\_keyword:] Header keyword observing date and time (in UTC). The format needs to be \mbox{YYYY-MM-DDTHH:MM:SS} (e.g. \\ \mbox{2018-02-28T23:34:01})  (standard: \mbox{DATE-OBS}). Other formats can be defined in the procedure \verb|get_obsdate|.
\end{description}


\noindent The file type and definition of the fibers is done by using the filename and header information. The assignment is done in the order given in Table~\ref{Tab:fiber_definition}. The result of this assignment is stored in a text file, which is shown to the user. The file can be edited (these information won't be overwritten if the script is re-executed). The following information is stored for each file in the raw data path (tab-separated):
\begin{table}
 \caption{Assignment of the fibers using the header keywords as given in the parameters of the configuration and filename. The science and calibration fibers are denoted with 'fiber1' and 'fiber2', respectively. Later assignment overwrites earlier ones. The filename is case-insensitive. '--' means no change has been done.}
 \label{Tab:fiber_definition}
 \begin{tabular}{l l l}
 \small
 condition 															& fiber1 & fiber2 \\
 \hline
 filename contains \verb|bias|										& bias	& bias \\
 filename contains \verb|dark|										& dark	& dark \\
 filename contains \verb|flat| but not \verb|sflat| 				& flat	& flat \\
 \verb|raw_data_imtyp_keyword| equals \verb|raw_data_imtyp_flat| 	&       & \\
 \hspace{1cm} and filename dosn't contain \verb|sflat| 				& flat  & flat \\
 filename contains \verb|arc|						   				& -- 	& wave \\
 \verb|raw_data_imtyp_keyword| equals \verb|raw_data_imtyp_bias| 	& bias	& bias \\
 \verb|raw_data_imtyp_keyword| equals \verb|raw_data_imtyp_dark| 	& dark	& dark \\
 none of the above and the filname doesn't start with \verb|arc|  & science & --   \\
 \end{tabular}
\end{table}

\begin{itemize}\setlength\itemsep{0em}
  \item Filename
  \item Type of light for the science fiber
  \item Type of light for the calibration fiber
  \item Exposure time in seconds
  \item Observation time
  \item Flag 'w', if the Arc spectrum should be extracted (important for single fiber spectrographs). Flag 'e', if the spectrum should be extracted. This can be modified in order to allow different processing of the images before extraction. The following options are possible:
    \begin{description}
      \item[e alone:] The processing as given in parameter \verb|extract_calibs_create_g| will be assigned.
      \item[e \textless obj \textgreater :] The processing as given in parameter \\ \verb|extract<obj>_calibs_create_g| will be assigned. If this parameter doesn't exist, then parameter \verb|extract_calibs_create_g| will be used.
      \item[ec \textless obj \textgreater :] The same as \textbf{e \textless obj \textgreater}, but instead of extracting each file induvidually, all files with \textbf{ec \textless obj \textgreater} will be combined into a file called \verb|master_<obj>.fits| and then this file is extracted.
      \item One raw file can be used for different extractions if several flags are combined with ',', e.g. \textit{e,ecSunAll,ecSunCentroid}.
    \end{description}
\end{itemize}

\subsection{Necessary information to calculate the barycentric correction}
\label{Section:barycentric_correction}
In order to calculate the barycentric correction the time of the observation (or Julian Date), the pointing on the sky, and the position of the observatory on earth need to be known. These information can be given in different ways. 

\begin{itemize}
 \item The mid-exposure date and time is derived from the image header using the keys given in the parameter \verb|raw_data_dateobs_keyword| and \verb|raw_data_exptim_keyword| (half of the exposure time). The pipeline can handle different standard formats (YYYY-MM-DDThh:mm:ss). If necessary, further formats can be added in the procedure \textit{get\_obsdate}.
 \item The position of the observatory will be extracted from the following sources (using the first available source in the following list:
 \begin{enumerate}\setlength\itemsep{0em}
  \item Reading latitude, longitude, and elevation from the header, using the the header keys defined in the beginning of procedure \textit{get\_barycent\_cor}: site\_keys, altitude\_keys, latitude\_keys, longitude\_keys (the first available entry of each list will be used, if necessary these lists can be extended).
  \item Using the site coordinates as given in the configuration file.
 \end{enumerate}
 \item The pointing of the telescope (RA and DEC) will be derived from the following sources (using the first available source in the following list:
 \begin{enumerate}\setlength\itemsep{0em}
  \item reading the object coordinates from a list of objects (see Chaper~\ref{Section:create_object_list_file}).
  \item Reading the object coordinates and epoch from the image header, using the header keys defined in the beginning of procedure \textit{get\_barycent\_cor}: ra\_keys, dec\_keys, epoch\_keys (the first available entry of each list will be used, if necessary these lists can be extended).
  \item If the object name contains sun or moon, then the coordinates of the sun/moon are calculated for the mid of the observing time.
 \end{enumerate}
\end{itemize}

%\subsubsection{get\_ut1\_offset: requested mjd is beyond end of IERS file}
%\label{Section:update_ssephem}
%If the message \verb|get_ut1_offset: requested mjd is beyond end of IERS file| appears, the data from Jet Propulsion Laboratory Development Ephemeris is out of date. It can be updated by running \verb|ssephem_update.py|. 

%\textit{At the moment DE403 is used (the CERES pipeline uses DE403). This can be changed by updating \verb|ssephem_update.py|, \verb|SSEphem/update_ssephem.py| (updating the procedure} SSEphemDownload \textit{, and at the beginning of \verb|procedures.py|.} However, this doesn't seem to have an impact on the resulting barycentric corrections.

\subsubsection{Creating a list of objects}
\label{Section:create_object_list_file}
If the coordinates of the object are not stored in the fits header, then they can be given using a the file specified in parameter \verb|object_file| (standard: \verb|object_list.txt|). The file can be located in the \verb|result_path| or \verb|raw_data_path| (the first one has higher priority). The file must contain one line per object. For each object the following tab-separated values need to be given:
\begin{enumerate}\setlength\itemsep{0em}
 \item Object name (the filename should start with the object name in order to be used)
 \item RA (hh:mm:ss.ss or as one number in degrees)
 \item DEC ($\pm$dd:mm:ss.ss or as one number in degrees)
 \item PM RA (mas/year, can be 0 in the most cases)
 \item PM DEC (mas/year, can be 0 in the most cases)
 \item Epoch of the coordinates (only the number, e.g. 2000 or 2015.5)
 \item Enable/Disable flag (1 for enabled)
 \item Mask to use. At the moment G2, K5, or M2 are possible options. Can be empty
 \item Velocity width to broaden the lines of the binary mask
\end{enumerate}


\subsection{Format of the extracted files}
Different types of extracted files are created. They are described in the following subsections.

\subsubsection{raw-data filename}
\label{section:extraction_data_format}
The final fits file contains the original header and some additional information, for example the calibration steps which were applied and some information about the flux collected in the different apertures. The data in the file is stored in a 3D array in the form: data type, aperture, and pixel. The data types are similar to the ones created by the CERES pipeline and are the following:
\begin{enumerate}
  \setcounter{enumi}{-1}
  \item 2D array with the wavelength for each aperture and pixel.
  \item Extracted spectrum without any modification.
  \item Measurement of the error the extracted spectrum (using the scatter of the residuals after fitting a 2d polynomalial to the background areas (noise in the dark/bias))
  \item Blaze corrected spectrum, calculated by dividing the extracted spectrum and the normalised flat spectrum.
  \item Error of the flat corrected spectrum (residuals of a polynomial fitted to the blaze corrected spectrum).
  \item Continuum normalised spectrum. The continuum is derived by fitting a polynomial to the flat corrected spectrum, using only areas of the spectrum where no lines are located. 
  \item Signal to noise ratio in the continuum, calculated from the residuals between continuum fit and measured continuum and the flux in the continuum.
  \item Mask with good areas of the spectrum. The following values are used:
  \begin{itemize}
    \item[1] good
    \item[0] no data available
    \item[0.1] saturated pixel in the extracted spectrum
    \item[0.2] bad pixel in the extracted spectrum
  \end{itemize}
  \item Spectrum of the calibration fiber, e.g. of the emission line lamp.
\end{enumerate}

\subsubsection{raw-data filename + \_harps\_e2ds}
This file contains the extracted spectrum without any modification in the same form as the \textit{e2ds} files created by the HARPS pipeline. The wavelength solution is stored in the header.

\subsubsection{raw-data filename + \_lin}
\label{Section:linearised_spectrum}
The extracted spectrum is linearised using a wavelength step as given in parameter \verb|wavelength_scale_resolution|. The wavelength spectrum is interpolated by using the weighted mean of the neighbouring data points with the wavelength difference as weights.

\subsubsection{raw-data filename + \_lin\_cont}
This file contains data in the same form as described in Chapter~\ref{Section:linearised_spectrum}, only that the continuum corrected data was linearised.

\subsubsection{inside single folder}
All the files are 2D arrays with the order/aperture as first and number of pixel in second dimension.
\begin{description}
 \item[raw-data filename + \_extr] Extracted spectrum with wavelength solution in IRAF format (wavelength solution without barycentric correction).
 \item[raw-data filename + \_extr\_bluefirst] Same as the entry before, but starting with the blue orders instead of the red orders.
 \item[raw-data filename + \_blaze] Blaze corrected spectrum with wavelength solution in IRAF format (wavelength solution without barycentric correction).
 \item[raw-data filename + \_blaze\_bluefirst] Same as the entry before, but starting with the blue orders instead of the red orders.
 \item[raw-data filename + \_wave] The wavelength for each aperture and pixel.
 \item[raw-data filename + \_weight] Mask with good areas of the spectrum.
\end{description}

\subsubsection{path\_csv\_terra + $<$object name$>$ + /data/YYYY-MM-DDHHMMSS.cvs files}
The data in here is used in order to measure RV with Terra (\url{https://drive.google.com/file/d/1xK-lYghFwpwtdXG9b4IbryYRd102q7So/view}). The barycentric corrected wavelength solution and the continuum corrected spectrum (multiplied by the bad-pixel mask) are used. See Chapter~\ref{Section:files_folders_csv_for_terra} for more information.

\subsection{Results from the pipeline}
\subsubsection{Preparing the data for one night}
\label{section:results_pipeline}
For each of the steps given in Chapter~\ref{Section:pipeline_steps_general} the following data will be created.

\noindent \textbf{Step 1:} The reduced and combined CCD images will be stored in the folder where the pipeline was run. The file name is \verb|master_<type>.fits|, where \verb|<type>| defines the different image types, e.g. bias, sflat, trace, or arc\_l.

\vspace{0.5em}\noindent \textbf{Step 2:} The trace of each scientific order is stored as a table in the file given in parameter \verb|master_trace_sci_filename| (standard: \textit{master\_traces\_sci.fits}). This is a table fits-file and contains one line for each order, normally starting with the reddest order, which is located on the left side of the CCD image. Each line contains the following information:
\begin{itemize}\setlength\itemsep{0em}
  \item Number of the aperture (starting at 0).
  \item Central pixel (in dispersion direction) for the polynomial fit along the center (Gaussian centre) of the trace.
  \item Parameters of a polynomial fit to the center of the trace (given in parameter \verb|polynom_traces_apertures|), e.g. 5 values if the trace is fitted with a polynomial of order 5.
  \item Central pixel (in dispersion direction) for the polynomial fit along the left limit of the trace. The limit is determined from the value given in parameter \verb|width_percentile|
  \item Parameters of a polynomial fit to the left limit of the trace (given in parameter \verb|polynom_traces_apertures|).
  \item Central pixel (in dispersion direction) for the polynomial fit along the right limit of the trace. The limit is determined from the value given in parameter \verb|width_percentile|
  \item Parameters of a polynomial fit to the right limit of the trace (given in parameter \verb|polynom_traces_apertures|).
  \item The lowest and highest pixel in dispersion axis, for which the trace can be identified.
  \item The last three entries of each line define the width of the trace: left border (where the flux raises over the value given in parameter \verb|width_percentile|), the right border (where the flux falls below \verb|width_percentile|), and the Gaussian width.
\end{itemize}
The identification of the traces can be checked easily in the file given in parameter \verb|logging_traces_im| (standard: \textit{traces\_in\_master\_trace1.png}). This file is located in the folder given in the parameter \verb|logging_path| (standard: \textit{logging}). An example is show in Fig.~\ref{figure_apertures_in_master_flat}.

\begin{figure} 
  \begin{center}
    \includegraphics[width=\textwidth]{./figures/orders_in_master_flat}
  \end{center} 
  \caption{Reduced CCD image of a white light flat (log10 gray scale) with the marked traces of the identified scientific orders/apertures (red). The extraction width (determined from the width given in parameter \textbf{width\_percentile} of the order multiplied with the value in parameter \textbf{extraction\_width\_multiplier}) is given in the dashed lines.
    \label{figure_apertures_in_master_flat}}
\end{figure}

%\vspace{0.5em}\noindent \textbf{Step 3:} The background map, 2d image is stored in the file given in parameter \verb|background_filename| (standard: \textit{background.fits}). Additionally a mask which provides the pixel which are used to create the background map is stored in the file given in parameter \verb|background_px_filename| (standard: \textit{background\_px.fits}).

\vspace{0.5em}\noindent \textbf{Step 3:} The traces of the apertures of the calibration fiber are stored in the file given in parameter \verb|master_trace_cal_filename| (standard: \textit{master\_traces\_cal.fits}). This is a table fits-file and contains the same information as the result of \textbf{Step 2}, only that the lowest order of the parameters of the polynomial fits are shifted (the curvature of the traces is kept the same). The result can be checked easily in the file given in parameter \verb|logging_arctraces_im| (standard: \textit{arctraces\_in\_master\_traces\_cal.png}). An example is show in Fig.~\ref{figure_arcapertures_in_master_arc}.

\begin{figure} 
  \begin{center}
    \includegraphics[width=\textwidth]{./figures/arcorders_in_master_arc}
  \end{center} 
  \caption{Reduced CCD image of a ThAr exposure (log10 gray scale) with the marked traces of the identified calibration orders/apertures (red). The extraction width (determined from the width given in parameter \textbf{width\_percentile} of the order multiplied with the value in parameter \textbf{extraction\_width\_multiplier}) is given in the dashed lines.
    \label{figure_arcapertures_in_master_arc}}
\end{figure}


\vspace{0.5em}\noindent \textbf{Step 4:} The wavelength solution is stored in a table fits-file given in parameter \verb|master_wavelensolution_filename| (standard: \textit{master\_wavelength.fits}). The parameters for each order are stored in one line. For each order the following values are stored:
\begin{itemize}
  \item Real order, as derived from the grating equation.
  \item Central pixel of the order (in dispersion direction).
  \item Parameters of a polynomial fit to the trace, e.g. 4 values if the dispersion axis is fitted with a polynomial of order 4.
  \item List of the wavelengths of all the identified reference lines in this order.
\end{itemize}

During the step to find the wavelength solution, the pipeline logs data similar to the following output:
\begin{lstlisting}[style=base, basicstyle=\tiny]
Info: To match the most lines in the arc with the old wavelength solution, a shift
of -2 orders, a multiplier to the resolution of 0.994, a shift of -10 px, and a
shift of 0.0 px per order needs to be applied. 1046 lines were identified. The
deviation is 0.1197 Angstrom.
Info: used 1054 lines. The standard deviation of the residuals between the lines and the fit is 0.0344 Angstrom (the average of the abs of the residuals is 0.0223 Angstrom). This converts into a resoution R = 183169. The Gaussian width of the emssion lines results in an R = 46223 +- 12192. The 2-pixel resolution (around the identified lines) is R = 72840 +- 4107.
Info: A 2d polynom fit with 5 orders in dispersion direction (along the traces) and 5 orders in cross-dispersion direction was used. With this solution, the offset between aperture and real orders is 75. With this offset, the standard deviation of the residuals between the central wavelengths and the grating equation is 0.042 Angstrom (abs of average is 0.0336 Angstrom). Using the original solution gives an offset of 75.

ap cenwav minwav maxwav range Ang/  name numb gausswi gausswi min_   max_   range_reflin
                               px             dth_avg dth_std reflin reflin _whole_order

0  7978.6 7894.7 8054.2 159.5 0.038 Ar I    2    1.78    0.58 7916.4 7948.2  98.1
0  7978.6 7894.7 8054.2 159.5 0.038 Th I    2    2.04    1.15 7937.7 8014.5  98.1
...
27 5800.1 5769.1 5854.3 85.2  0.027 Ar I    2    3.06    0.15 5802.1 5834.3  44.6
27 5800.1 5769.1 5854.3 85.2  0.027 Th I    6    2.31    0.41 5789.6 5832.4  44.6
-1   -1.0   -1.0   -1.0 -1.0  1.000 Ar I  148    2.07    0.61 5802.1 7948.2  2146.1
-1   -1.0   -1.0   -1.0 -1.0  1.000 Th I  376    2.04    0.66 5789.6 8014.5  2224.9
\end{lstlisting} 
Thereby the table contains the following information:
\begin{description}
  \item[apert] Aperture of the trace, starting with 0 for the reddest aperture ($\tilde{m}$). To get the real order the offset $m_0$ is given in the text before (here: 72). The offset is determined using two different ways. First the data is compared to the grating equation $\lambda \propto m_0 + \tilde{m}$. In Practical this was done by searching for the smallest slope in the formula $y = (m_0 + \tilde{m})\lambda_c$, were $\lambda_c$ is central wavelength of each order. The second value for the real order offset is determined from the shift towards the previous wavelength solution. Both values for the offset should be the same. Only the first value is saved in the file for the wavelength solution.
  \item[cenwave] Central wavelength of the order, determines the zero point of the wavelength solution.
  \item[minwave, maxwave, ranwave] Minimum and maximum wavelength, and wavelength range which is covered by the trace of this order.
  \item[Ang/px] Resolution in $\frac{\AA}{\mathrm{px}}$ at the central wavelength.
  \item[name] Type of the reference line. If different types of reference lines were found in the order then a output for each available type is created.
  \item[number] Number of reference line for this type and order.
  \item[gausswidth\_avg, gausswidth\_std] Average and standard deviation of the Gaussian width of the emission lines
  \item[min\_refline, max\_refline] Minimum and maximum wavelength of the reference lines of this type and order
  \item[range\_reflines\_whole\_order] Wavelength range which was covered by reference lines for this order (independent of type of the line)
\end{description}
The last lines give the information for all apertures. Columns, for which no useful information can be derived show the value \verb|-1|.

\begin{figure} 
  \begin{center}
    \includegraphics[width=\textwidth]{./figures/arc_line_identification_positions}
  \end{center} 
  \caption{Reduced CCD image of a ThAr exposure (log10 gray scale) with the identified lines from the reference catalogue (red). Only this set of data was used to create the wavelength solution. The remaining lines of the reference catalogue, which weren't used for fitting the solution are shown in green. The data on an order by order basis is shown in Figure~\ref{figure_arc_line_identification_spectrum}.
    \label{figure_arc_line_identification_positions}}
\end{figure}

\begin{figure} 
  \begin{center}
    \includegraphics[width=\textwidth]{./figures/screenshot_spectral-atlas}
  \end{center} 
  \caption{One page (aperture 13, real order 88) of the spectral atlas (file created from parameter \textbf{logging\_arc\_line\_identification\_spectrum}) created from the wavelength solution. Blue shows the spectrum of the emission lines in the long and orange the emission lines in the short exposure. The identified lines are marked in red, with the length of the marker being proportional to the intensity of the line as given in the \textbf{reference\_catalog} (length is reset for each order). Green shows a subset of the non-identified lines from the \textbf{reference\_catalog}, this means the green markers should normally be shorter than the red ones. Problems with an overcrowded \textbf{reference\_catalog} is visible at a few places (e.g. 6466\,\AA), for better wavelength solutions the line catalogue should be cleared of bad lines.
    \label{figure_arc_line_identification_spectrum}}
\end{figure}


\begin{figure} 
  \begin{center}
    \includegraphics[width=\textwidth]{./figures/arc_line_identification_residuals}
  \end{center} 
  \caption{Residuals between the identified catalogue lines and the wavelength solution. Colorcoded are the different apertures.
    \label{figure_arc_line_identification_residuals}}
\end{figure}

\vspace{0.5em}\noindent \textbf{Step 5:} The normalised white light flat is stored in the file given in parameter \verb|master_flat_spec_norm_filename| (standard: \textit{master\_flat\_spec\_norm.fits}). The extraction and data format is described in Chapter~\ref{section:extraction_data_format}

\subsubsection{Extracting the science data and radial velocity analysis}
\paragraph{Files in folder given in parameter path\_rv\_ceres (standard: ceres\_rv\_output/}
This step is only done, if the Ceres pipeline is installed and \verb|path_ceres| is set correctly to the base folder of Ceres and the sub-folders \textit{utils/Correlation}, \textit{utils/GLOBALutils}, \textit{utils/OptExtract}, and \textit{utils/CCF} exist.

\begin{description}
  \item[*\_$<$mask$>$.pdf:] Cross-correlation function between object spectrum and the template.
  \item[pkl-files:] Data used to plot the cross-correlation function in the python-pickle format.
  \item[stellar\_pars.txt-files:] Stellar parameters of the object: $T_{eff}$, $\log g$, $Z$, $v\sin i$, $vel0$
\end{description}

\paragraph{Files and folders in folder given in parameter path\_csv\_terra (standard: terra\_rv\_data}
\label{Section:files_folders_csv_for_terra}
The data of the individual objects are stored in this folder in the subfolder \textit{object name + /data/}. If Terra is installed and \verb|terra_jar_file| is set correctly to the Terra \textit{PRV.jar}-file, then Terra will be run on each \textit{object name} within the folder. The results of the radial velocity analysis will be stored in \textit{object name + /results/synthetic.rv}.

It is possible to include the information from previous nights of the same object by linking or copying the \textit{.csv}-files into the corresponding \textit{data/}-folders and rerunning \verb|python <path to scripts>/reduction_day.py|. Please note that in order to this, the number of orders and the number of extracted pixel has to be always the same.

% -------------------------------------------------------------------------------------------


\newpage
\section{Seting up the pipeline}

\subsection{Creating a new wavelength solution}
\label{section:create_new_wave_solution}
If no previous wavelength solution exist, then wavelengths and pixel need to correlated manually. In this case the parameter \verb|original_master_wavelensolution_filename| needs to point to a file, which does not exist (e.g. \textit{master\_wavelength\_manual.fits}). Then the python scrip can be run normally. It will stop after searching for the lines in the emission line spectra. The order and pixel position of all identified lines are stored in the file given in parameter \verb|logging_found_arc_lines|. This file can be opened and the corresponding wavelengths can be added to some of the lines. I have found that providing 1.5 lines per order is enough for the pipeline to do the rest. The lines should cover as much of the CCD image as possible.

The correlated data needs to be saved into file \verb|arc_lines_wavelength.txt| with the following tab-separated entries:
\begin{itemize}
  \item Aperture (starting at 0)
  \item Real order (bigger than 0, usually between 40 and 120)
  \item Pixel
  \item Wavelength
  \item (Type of the line (e.g. ThI, NeII) ).
\end{itemize}

Afterwards the script can run again and will use this data to create a new wavelength solution.


\subsection{Setting up a new account or a new camera}
When setting up a new camera or a new account paths and parameters need to be adjusted. The following list explains necessary changes and how to determine parameters which need to be changed.
\begin{description}
  \item[badpx\_mask\_filename] : Insert path to the bad-pixel mask. Use 'NA', if no bad-pixel mask is needed.
  \item[reference\_catalog] : Change the path to the catalogue of the reference lines. The file contains one entry per line, each entry consists of tab-separated wavelength, line strength, and element. Line strength can be empty.
  \item[rotate\_frame, flip\_frame] : The CCD image needs to be aligned in a way that the cross-dispersion axis is along vertical direction and the dispersion axis is along the horizontal direction, AND that the wavelength in dispersion direction is increasing with higher pixel number by providing the necessary angle for \verb|rotate_frame|. If necessary the image can be flipped (\verb|flip_frame = True|) after the rotation so that the wavelength in cross-dispersion direction decreases with increasing pixel number (blue orders on the right and the red orders on the left).
  \item[width\_percentile] Only pixel with more flux than the value given in \verb|width_percentile| (of the maximum flux) will be extracted. The extraction width can be varied later using the parameters \verb|extraction_width_multiplier| and \verb|arcextraction_width_multiplier|. The covered area can be checked in the logged images given in the parameters \verb|logging_traces_im| and \verb|logging_arctraces_im|. %In case of a real Gaussian profile, the full width at half maximum and Gaussian width are connected with $FWHM = 2.35482\cdot w_{\mathrm{Gauss}}$.
  \item[bin\_search\_apertures] : In order to speed up the search for the traces, heavy binning should be applied. However, the value for the cross-dispersion axis should to chosen in a way, that neighbouring orders are still separated. This can be checked in the images \verb|flat_binned.fits|.
  \item[arcshift\_side] : Position of the calibration traces compared to the science traces. Can be 'left', 'right', or 'center'. The later option implies, that only one fiber exists.
  \item[raw\_data\_imtyp\_keyword, raw\_data\_imtyp\_*] : Put the correct information for the image type header key here. 
  \item[raw\_data\_exptim\_keyword, raw\_data\_dateobs\_keyword] : Use the right header keywords for the exposure time and the observation date. The format should be \verb|%Y-%m-%dT%H:%M:%S.%f| or\footnote{\url{https://docs.python.org/2/library/datetime.html\#strftime-and-strptime-behavior}} \verb|%Y-%m-%dT%H:%M:%S|. More formats can be added in the procedure \textit{get\_obsdate}.
  \item[raw\_data\_timezone\_cor] In the unlikely case, that the date and time stored in \verb|raw_date_timezone_cor| is not UTC, the time zone correction can be given here. Numbers will be positive east of UTC and negative west of UTC, e.g. +7 for Bangkok time or -10 for Hawaii.
  \item[standard\_calibs\_create] : Define the standard CCD processing, if necessary (see Chapter~\ref{Section:parameters_CCD_proc} for options).
  \item[site, altitude, latitude, longitude] : If the site information is not stored in the header (see Chapter~\ref{Section:barycentric_correction}), then the information can be stored in the configuration file.
%  \item[] : 
\end{description}

\noindent Further settings are described in Chapter~\ref{Section:steps_new_data_set}.

\subsection{Create a bad pixel mask}
\noindent The bad pixel masked used by the pipeline is fits file which consists of a 2 dimensional image consisting of '1' for good data and '0' for bad pixels. It can be created by the script \verb|create_badpx_mask.py|, but this is script is really work in progress at the moment.

% -------------------------------------------------------------------------------------------

\newpage
\section{Post-extraction analysis}

% -------------------------------------------------------------------------------------------
\noindent Once the science spectra were extracted these files can be analysed more in detail. 

\subsection{Plotting the data}

To plot the results the python program \verb|plot_img_spec.py| can be used. This script read the files given in the file \verb|plot_files.lst| and will plot at the beginning all data. Further limitations of the plotted data can be done using the UI. For a plot in different axis the first text box can be used. See the list below for options. For plotting only data from a subsection of files, the first text boxes 'Which file' and 'Exclude' need to be used. For plotting only a subsection of data types the second text boxes with 'Which data' and 'Exclude' are used to define this. For plotting only some apertures, the last text boxes are used (see an example in Fig.~\ref{figure_plotting_results_example1} and \ref{figure_plotting_results_example2}).

\begin{figure} 
  \begin{center}
    \includegraphics[width=\textwidth]{./figures/screenshot_plot_img_spec}
  \end{center} 
  \caption{An example of how to plot the extracted data. Shown are the solar spectra of entry 0 and 14 in the plot\_files.lst file. The graph shows the continuum normalised flux (data type 5), plotted over the wavelength (w). Only apertures 14 and 16 are shown.
    \label{figure_plotting_results_example1}}
\end{figure}

\begin{figure} 
  \begin{center}
    \includegraphics[width=\textwidth]{./figures/screenshot_plot_img_spec_lomb_scargle_fft}
  \end{center} 
  \caption{Another example of how to plot the extracted data. Shown is the Lomb-Scargle Periodogram for the white light spectra of entry 5 to 7, 20, 24, and 44 in the plot\_files.lst file. The extracted spectra (data type 1) of apertures 2, 12, and 29 and their corresponding wavelength solution was used as basis for the calculations.
    \label{figure_plotting_results_example2}}
\end{figure}

The following options for axis plotting exist:
\begin{description}\setlength\itemsep{0em}
  \item [] (empty): The flux is plotted against the pixel along the CCD in dispersion direction.
  \item [w] : The flux is plotted against the wavelength (stored in data type 0).
  \item [f] : The Fourier transformation is plotted against the period (in pixel). 
  \item [l] : The Lomb-Scargle-Periodogram is plotted against the period (in pixel).
  \item [wl] : The Lomb-Scargle-Periodogram is plotted against the period (in wavelength). If you look for periodic signals in the spectrum, this is what you very probably should use. 
\end{description}


%\subsection{Finding the radial velocity }

%\noindent The radial velocity measurement is based on the \textit{CERES} pipeline. Thereby a template is cross correlated with the scientific spectrum. For the analysis the following steps need to be run:
%\begin{lstlisting}[style=base]
%ls extracted/*.fits > analysis_files.lst
%python <path to script>/find_rv.py
%\end{lstlisting}


% -------------------------------------------------------------------------------------------


\newpage
\section{Extracting data from other spectrographs}

\subsection{Extracting HARPS data}

\subsubsection{Getting the data}
% Ceres observations with HARPS: http://www.eso.org/public/archives/releases/sciencepapers/eso1609/eso1609a.pdf
% HD 10180: G1V star with 7 planets: http://adsabs.harvard.edu/abs/2011A%26A...528A.112L
Search and download the data from \url{http://archive.eso.org/eso/eso_archive_main.html}. Check only 'HARPS/LaSilla'. For example data select night '2015 07 30' to find data of Ceres or use 2010 10 23/25 for HD\,10180 observation. Then download the data (save the download request script, cd to the folder, and run \verb|sh  downloadRequest<Number>script.sh|). The raw data (*fits.Z) can be extracted with:
\begin{lstlisting}[style=base]
gunzip *
cat <<EOT > extract_single_chip.py
#!/usr/bin/python
# -*- coding: utf-8 -*-
import os
from astropy.io import fits

os.system('mkdir -p red_chip blue_chip')
for entry in os.popen('ls -1 *.fits').readlines():
    im_r = fits.getdata(entry[:-1],2)
    im_b = fits.getdata(entry[:-1],1)
    im_head_r = fits.getheader(entry[:-1],2)
    im_head_b = fits.getheader(entry[:-1],1)
    im_head0 = fits.getheader(entry[:-1],0)
    fits.writeto('red_chip/'+entry[:-1], im_r, \
                 im_head0, overwrite=True)
    fits.writeto('blue_chip/'+entry[:-1], im_b, \
                 im_head0, overwrite=True)
EOT
python extract_single_chip.py
\end{lstlisting}


\subsubsection{Preparing for data extraction}

\noindent The following replacements are necessary in the conf.txt file:
\begin{itemize}\setlength\itemsep{0em}
  \small
  \item \verb|subframe                = [4096,2048,0,50]|
  \item \verb|rotate_frame            = 180|
  \item \verb|bin_search_apertures    = 20,2|
  %\item \verb|arcshift_range    = [-12, -20]| (red chip),\\ \verb|arcshift_range  = [-12, -20]| (blue chip)
  \item \verb|arcshift_side           = left|
  \item \verb|original_master_wavelensolution_filename = master_wavelensolution_manual.fits|. The file \verb|arc_lines_wavelength.txt| needs to be created (Chapter~\ref{section:create_new_wave_solution}).
  \item \verb|arc_lines_catalog 	  = <path>reference_lines_ThAr-HARPS_Ceres.txt|
  \item \verb|use_catalog_lines 	  = ThI, ArI, ?, NoID, ArII, ThII|
  \item \verb|raw_data_imtyp_keyword  = OBJECT|
  \item \verb|raw_data_imtyp_bias     = BIAS,BIAS|
  \item \verb|raw_data_imtyp_sflat    = LAMP,DARK,TUN|
  \item \verb|raw_data_imtyp_flatarc  = LAMP,LAMP,TUN|
  \item \verb|raw_data_imtyp_arc      = WAVE,WAVE,THAR2|
  \item \verb|bias_calibs_create_g    = subframe|
  \item \verb|trace1_calibs_create_g  = subframe, bias|
  \item \verb|trace2_calibs_create_g  = subframe, bias|
  \item \verb|arc_calibs_create_g     = subframe, bias|
  \item \verb|flatarc_calibs_create_g = subframe, bias|
  \item \verb|extract_calibs_create_g = subframe, bias|
  \item \verb|polynom_order_traces    = [2,3]|
  \item \verb|polynom_order_intertraces = 2,3|
\end{itemize}

\noindent Afterwards, \verb|prepare_file_list.py| and \verb|reduction_day.py| can be run as described above.

\subsubsection{HARPS data reduced by the CERES pipeline}
To compare the results from the EXOhSPEC pipeline, it can also be compared with the results from the CERES pipeline (\url{https://ui.adsabs.harvard.edu/#abs/2017PASP..129c4002B/abstract}, \url{https://github.com/rabrahm/ceres}). The extraction can be run with:
\begin{lstlisting}[style=base]
cd ~/software/ceres-master/harps/
python harpspipe.py /data/ronny/Reduced/20180313_harps_sol_ceres_red/ -do_class
\end{lstlisting}

The pipeline produces the following files:
\begin{description}
  \item[spec.co.B.fits.S, spec.co.R.fits.S] 
  \item[spec.ob.B.fits.S, spec.ob.R.fits.S] 
  \item[proc/results.txt] Results of the cross-correlation, including the radial velocity.
  \item[proc/*.fits] The reduced images, in the similar format as produced by the EXOhSPEC pipeline.
\end{description}

Please note that the CERES pipeline uses both the red and the blue HARPS chip in order to determine the radial velocities (the data of the blue chip can be avoided by changing \verb|spec| into \verb|spec[:,:26,:]| in \verb|harpspipe.py|, lines 1507 and 1530). Furthermore, a cosmic ray correction is applied. The extracted spectra have the same features as when extracting data with the EXOhSPEC pipeline. A wavelength shift (depending on the order) is visible between the spectra. This translates into a RV shift of $\Delta RV \approx 79$\,km/s (independent of order, no instrumental velocity drift were applied to EXOhSPEC).



\subsubsection{HARPS data reduced by the ESO Phase 3 pipeline}
% wrong: http://archive.eso.org/wdb/wdb/eso/repro/form
The reduced data can be found at: \url{http://archive.eso.org/wdb/wdb/adp/phase3_spectral/form}. Select 'ESO-3.6' and 'HARPS'. For example data use Date Obs '2015-07-30..2015-08-01' or the Run/Program ID from the results of the query for the raw data (make sure to use the ID of the science, not the calibration data). The download the data. The reduced data (*.tar) can be extracted using
\begin{lstlisting}[style=base]
cat *.tar | tar -xvf - -i
\end{lstlisting}

The data is reduced in the following way\footnote{\url{http://www.eso.org/rm/api/v1/public/releaseDescriptions/72}}:
\begin{itemize}\setlength\itemsep{0em}
  \item bias subtraction via overscan region
  \item dark subtraction via values stored in a database
  \item order extraction into 'e2ds' files
  \item flat fielding (flat/blaze function is used as flat)
  \item wavelength calibration
  \item order matching into 1D files 's1d'
  \item cross correlation for RV -> 'ccf' and 'bis' files
  \item correction for instrumental drift using the calibration fiber
\end{itemize}

The following files are available:
\begin{description}
  \item[ADP.*.fits (primary file)] Table with wavelength, flux (, and error) in 0.01\,\AA\ steps. The files are in random order, check DATE-OBS to sort them.
  \item[HARPS.*\_bis\_\textless sptype\textgreater\_A.fits] Bisector from cross correlation with the \textless sptype\textgreater\ mask.
  \item[HARPS.*\_ccf\_\textless sptype\textgreater\_A.fits] Cross correlation function matrix for mask for \textless sptype\textgreater.
  \item[HARPS.*\_ccf\_\textless sptype\textgreater\_A.tbl]  Cross correlation function summary table (ASCII) with extracted radial velocity per each order.
  \item[HARPS.*\_e2ds\_\textless fibre\textgreater.fits] 2D extracted spectrum with wavelength solution in the header.
  \item[HARPS.*\_INT\_GUIDE.fits] Image from the integrated guiding camera (star centred on the fiber).
  \item[HARPS.*\_s1d\_\textless fibre\textgreater.fits] 1D extracted full spectrum, wavelength calibrated, in the solar system barycentric frame.
\end{description}

The wavelength solution in the \verb|e2ds| files is stored in the header\footnote{See page 22 in \url{https://www.eso.org/sci/facilities/lasilla/instruments/harps/doc/DRS.pdf}}. The order numbering starts at 0 (bluest order) and the pixel numbering \textbf{probably} starts at 0, too (bluest pixel). The \verb|e2ds| files can be converted to the EXOhSPEC format by using the script \verb|reduced_harps_to_exohspec.py|.

\paragraph{Results}
The extracted calibration spectrum and the science spectrum are very similar. Emission and absorption lines are at the same wavelength. The extracted flux is about 10-12\% lower and the noise slightly higher.

Few problems occur when comparing the data of reduced with this pipeline and the data from the ESO Phase 3 pipeline:
\begin{enumerate}\setlength\itemsep{0em}
  \item The bias correction can't be performed, as usually only one bias frame is available.
  \item Overscan correction is not implemented in the pipeline.
  \item No cosmic ray removal is applied.
  \item Different flat fielding.
  \item Traces have a fixed width, therefore the S/N of the extracted data might decrease slightly.
  \item Only one CCD is processed at a time, which might decrease the precision of the wavelength solution.
  \item The wavelength shift between science and calibration fiber is not determined (yet).
\end{enumerate}

\subsubsection{Analysing the reduced HARPS data with TERRA}
For more information about TERRA please refer to the literature\footnote{\url{https://ui.adsabs.harvard.edu/\#abs/2012ApJS..200...15A/abstract}}. The following files are used by TERRA:
\begin{description}
  \item[HARPS.*\_bis\_\textless sptype\textgreater\_A.fits] Bisector from cross correlation with the \textless sptype\textgreater\ mask.
  \item[HARPS.*\_ccf\_\textless sptype\textgreater\_A.fits] Cross correlation function matrix for mask for \textless sptype\textgreater.
  \item[HARPS.*\_e2ds\_\textless fibre\textgreater.fits] 2D extracted spectrum with wavelength solution in the header.
\end{description}

\textit{Todo: more}

\subsection{Extracting MRES data}

The testing of the pipeline was done for the MRES data taken on 2018-11-27.

\noindent The following replacements/insertions are necessary in the conf.txt file. 
\begin{itemize}\small\setlength\itemsep{-0.1cm}
  \item \verb|subframe                 = [1201,511,380,0]|
  \item \verb|rotate_frame             = 270|
  %\item \verb|arcextraction_width_multiplier = 1|
  \item \verb|maxshift                 = 5|
  \item \verb|bin_search_apertures     = 10,1|
  \item \verb|bin_adjust_apertures     = 2,1|
  \item \verb|width_percentile         = 5|
  \item \verb|arcshift_side            = center|
  \item \verb|raw_data_imtyp_bias      = NA|
  \item \verb|raw_data_imtyp_dark      = NA|
  \item \verb|raw_data_imtyp_flat      = NA|
  \item \verb|raw_data_exptim_keyword  = EXPOSURE|
  \item \verb|raw_data_dateobs_keyword = DATE|
  \item \verb|arc_calibs_create_g      = subframe,bias|
  \item \verb|trace1_calibs_create_g   = subframe,bias|
  \item \verb|trace2_calibs_create_g   = subframe,bias|
  \item \verb|extract_calibs_create_g  = subframe,bias|
  \item \verb|flatarc_calibs_create_g  = subframe,bias|
  \item \verb|wavelengthcal_calibs_create_g = subframe,bias|
  \item \verb|site        = TNT|
  \item \verb|altitude    = 2457|
  \item \verb|latitude    = 18.59055|
  \item \verb|longitude   = 98.48655|
  \item \verb|extracted_bitpix         = -32|
\end{itemize}


% -------------------------------------------------------------------------------------------


\newpage
\section{Fixing problems: The results are not as expected}
\label{Section:Problem_solution}
In the following Chapters a few ideas of how to check and fix common problems are given. The following standard names are assumed.
\begin{itemize}\small\setlength\itemsep{-0.2cm}
  \item \verb|object_file = object_list.txt|
  \item \verb|master_trace_sci_filename           = master_traces_sci.fits|
  \item \verb|master_trace_cal_filename           = master_traces_cal.fits|
  \item \verb|master_wavelensolution_filename     = master_wavelength.fits|
  \item \verb|logging_path              = logging/|
  \item \verb|logging_trace1_binned     = mstr_trace1_binned.fits|
  \item \verb|logging_traces_binned     = sci_trace1_binned.fits|
  \item \verb|logging_traces_im_binned  = traces_in_master_trace1_binned.png|
  \item \verb|logging_traces_im         = traces_in_master_trace1.png|
  \item \verb|logging_find_arc_traces   = arctraces_find.png|
  \item \verb|logging_arctraces_im      = arctraces_in_master_trace2.png|
  \item \verb|logging_arc_line_identification_residuals = arc_line_identification_residuals.png|
  \item \verb|logging_arc_line_identification_spectrum  = arc_line_identification_spectrum.pdf|
  \item \verb|logging_arc_line_identification_positions = arc_line_identification_positions.png|
%  \item \verb||
\end{itemize}
If you modified the parameters, please use yours instead of the given ones in the following Chapters.

If parameters are changed while working through the following steps. Some of the already created files need to be removed before the pipeline can re-run with the better settings. In the following chapters, each correction step should name the first value of the following list, that need to be removed (error messages because of missing files can be ignored). Afterwards \verb|reduction_day.py| can be run again.
\begin{lstlisting}[style=base]
rm master_*
rm logging/sci_trace1_binned.fits
rm master_traces_sci.fits
rm master_traces_cal.fits
rm master_wavelength*.fits
rm extracted/*
\end{lstlisting}


\subsection{Are the traces (of the science fiber) identified correctly?}
\begin{itemize}
  \item \textbf{logging/traces\_in\_master\_trace1.png}: Are the orders identified correctly? If yes, go to next chapter.
  \item If a lot of unexposed area is located on the image borders, adjust parameter \verb|subframe| to the correct image set. Remove everything after \textit{master\_*}.
  \item If the orders are not running from up to down in the image, the adjust paramter \verb|rotate_frame|.  Remove everything after \textit{master\_*}.
  \item If noise was marked as order, run \verb|remove_orders.py| and remove the wrong orders. All depending calculations will run again.
  \item If orders are missing check \textbf{logging/traces\_in\_master\_trace1\_binned.png}. If the orders are marked there correctly then adjust parameter \verb|bin_adjust_apertures|, so that the echelle orders are well separated and only pixel with similar amount of flux are median combined. Remove everything after \textit{master\_traces\_sci.fits}.
  \item If orders are missing check \textbf{logging/mstr\_trace1\_binned.fits}. Very likely, too heavy binning was used and the orders are not destinguishable or half of the binning area consists of background pixel. Adjust parameter \verb|bin_search_apertures|. Remove everything after \textit{logging/sci\_trace1\_binned.fits}.
\end{itemize}


\subsection{Are the traces (of the calibration fiber) identified correctly?}
\begin{itemize}
  \item \textbf{logging/arctraces\_in\_master\_trace2.png}: Are the orders identified correctly? If yes, go to next chapter.
  \item Be sure, that all echelle orders from the science fiber are well separated from the orders of the calibration fiber. If necessary change the orientation of the bifurcated fiber in the setup (angel between bifurcated fiber and cross-disperser). Take new data, start in a new folder.
\end{itemize}


\subsection{Is the wavelength solution correct?}
\begin{itemize}
  \item \textbf{logging/arctraces\_in\_master\_trace2.png} (if emission line lamp spectrum, otherwise \textbf{logging/arc\_line\_identification\_positions.png} (ignore the written wavelengths)): If the wavelengths of the emission lines is not increasing from up to down along the individual orders or if the redder orders are not on the left side of the image, adjust parameters \verb|rotate_frame| and \verb|flip_frame|. Remove everything after \textit{logging/sci\_trace1\_binned.fits}.
  \item \textbf{logging/arc\_line\_identification\_residuals.png}: If the most dots fall on the x-axis , go to next chapter. If most dots fall on a sinusoidal line, increase the number of orders in parameters \verb|polynom_order_traces| or \verb|polynom_order_intertraces|. Remove everything after \textit{ master\_wavelength*.fits}.
  \item \textbf{logfile}: search for the (last) line containing:
  \begin{lstlisting}[style=base]
 standard deviation of the residuals between the lines and the fit
  \end{lstlisting}
  A high number of lines should have been identified to a reasonable precision (compare to a previous night). If all is the case, go to next chapter.
  \item textbf{logging/arc\_line\_identification\_spectrum.pdf}: The emision lines in the extracted spetrum should match with the brightest lines from the catalogue (red wavelengths, marker lengths is an indication for the brightness). If yes, go to next chapter.
  \item The lines in the above spectrum are not matching at the borders. Decrease or increase parameter \verb|polynom_order_traces|. Decrease or increase the values in \verb|opt_px_range|. Remove everything after \textit{ master\_wavelength*.fits}.
  \item The lines are completely off. Compare \textbf{logging/arctraces\_in\_master\_trace2.png} in the current directory and in the directory from where the the original wavelength solution are taken (\verb|original_master_wavelensolution_filename|). Check, that the parameters \verb|order_offset|, \verb|px_offset_order|, and \verb|px_offset_order| are large enough to cover the change between the two nights. Be sure the values are not too big. Remove everything after \textit{master\_wavelength*.fits}.
\end{itemize}


\subsection{Are the object and telescope coordinates correct, is the handling of time right?}
\begin{itemize}
  \item Was the right object used from \textbf{object\_list.txt}?
  \item Compare the barycentric velocity with other calculators. Are the object and telescope coordinates right? Is the time zone correct? If not, check parameters \verb|raw_data_dateobs_keyword|, \verb|raw_data_timezone_cor|, \verb|site|, \verb|latitude|, and \verb|longitude|.
\end{itemize}


\subsection{Further help}
If you observe strange behaviour, please contact Ronny. Access to the reduction folder would be preferable.

% -------------------------------------------------------------------------------------------


\newpage

\appendix

\section{Module dependencies if not using Anaconda (needs update)}
\label{section:module_dependency}
\noindent This program relies on the following modules in python 2.7

\begin{itemize}\setlength\itemsep{0em}
\item numpy
\item os
\item sys
\item time
\item datetime
\item operator
\item copy
\item random
\item warnings
\item tqdm
\item pickle
\item json
\item astropy
\item scipy
\item matplotlib
%\item[] {\bf if python2:}
\item Tkinter
\item collections
%\item[] {\bf if python3:}
%\item tkinter
\item ephem
\item math.radians
\item statsmodels.api
%\item numpy (1.11.2)
%\item astropy (1.1.2)
%\item matplotlib (1.5.1)
%\item tqdm (4.4.0)
%\item skimage (0.12.3)
\end{itemize}

% Other versions may work but these are the ones tested.


% -------------------------------------------------------------------------------------------


\newpage
\section{Short introduction to reduction of CCD images}

The data stored in CCD images is affected by the physical parameters of the individual pixels and way the readout electronics work. Therefore each scientific frame needs to be corrected (pixel by pixel) with the formula:
\begin{equation}
  \mathrm{reduced\ Science} = \frac{\mathrm{raw\ Science} - \mathrm{master\ Bias} - \mathrm{master\ Dark}}{\mathrm{master\ Flat}}\,.
\end{equation}
The master Dark should have the same exposure time as the Science frame and the master Flat should be normalised in order to keep the flux levels. To create the master Dark and master Flat, the following steps are necessary:
\begin{equation}
  \mathrm{master\ Dark} = \mathrm{raw\ Dark} - \mathrm{master\ Bias}
\end{equation}
\begin{equation}
  \mathrm{master\ Flat} = \mathrm{raw\ Flat} - \mathrm{master\ Bias} - \mathrm{master\ Dark}\,.
\end{equation}
The master Dark used for the creation of the master Flat should have the same exposure time as the Flat and needs to be corrected with the Bias. The master Bias in each of the formulas can be different.

In order to decrease the noise levels, each of the master file should be created by median combining several (corrected) images together. If the brightness of the individual flats vary, then the flats should be weighted by their median flux before combining them. Combining all steps leads to the formula
\begin{equation}
  \label{eq:reduction_full}
  \mathrm{reduced\ Science} = \frac{\mathrm{raw\ Science} - B_S - (D_S - B_{D_S})}{F - B_F - (D_F - B_{D_F})}\,,
\end{equation}
where $B_S$ is the master Bias, created by combining biases taken at a similar time as the science frame, $D_S$ is the master Dark, created of darks with the same exposure time as the science frame. In case the bias level and noise don't change during the night, then Equation~\ref{eq:reduction_full} changes to
\begin{equation}
  \mathrm{reduced\ Science} = \frac{\mathrm{raw\ Science} - D_S}{F - D_F}\,.
\end{equation}

In case the dark level is negligible and the Bias level is constant, then Equation~\ref{eq:reduction_full} changes to
\begin{equation}
  \mathrm{reduced\ Science} = \frac{\mathrm{raw\ Science} - B}{F - B}\,.
\end{equation}


In the pipeline always the individual frames are corrected before frames are combined.



\end{document}



\begin{lstlisting}[style=base]

\end{lstlisting}
